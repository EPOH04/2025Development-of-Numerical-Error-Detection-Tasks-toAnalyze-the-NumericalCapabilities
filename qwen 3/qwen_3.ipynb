{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-10T09:37:27.098768Z",
     "iopub.status.busy": "2025-05-10T09:37:27.098532Z",
     "iopub.status.idle": "2025-05-10T09:37:31.040936Z",
     "shell.execute_reply": "2025-05-10T09:37:31.040010Z",
     "shell.execute_reply.started": "2025-05-10T09:37:27.098745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jsonlines\n",
      "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines) (25.3.0)\n",
      "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Installing collected packages: jsonlines\n",
      "Successfully installed jsonlines-4.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T11:43:25.282129Z",
     "iopub.status.busy": "2025-05-29T11:43:25.281848Z",
     "iopub.status.idle": "2025-05-29T11:43:28.803735Z",
     "shell.execute_reply": "2025-05-29T11:43:28.803120Z",
     "shell.execute_reply.started": "2025-05-29T11:43:25.282112Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/site-packages (4.52.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/site-packages (from transformers) (0.32.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (2025.1.31)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-06-04T11:13:21.151113Z",
     "iopub.status.busy": "2025-06-04T11:13:21.150833Z",
     "iopub.status.idle": "2025-06-04T11:14:48.212135Z",
     "shell.execute_reply": "2025-06-04T11:14:48.211666Z",
     "shell.execute_reply.started": "2025-06-04T11:13:21.151096Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-06-04 19:13:29,071 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 5/5 [01:19<00:00, 15.81s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-35): 36 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (down_proj): Linear(in_features=12288, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import List, Dict, Tuple\n",
    "import random\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "import time\n",
    "import logging\n",
    "import jsonlines\n",
    "\n",
    "# 设置日志\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1. 加载 Qwen3 模型和分词器\n",
    "model_name = \"dataroot/models/Qwen/Qwen3-8Br\"\n",
    "model_loc=\"/mnt/workspace/dataroot/models/Qwen/Qwen3-8B/qwen_model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_loc,local_files_only=True)\n",
    "tokenizer.padding_side = 'left'\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_loc,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    local_files_only=True\n",
    ")\n",
    "model.eval()  # 设置为评估模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-06-02T08:42:35.699568Z",
     "iopub.status.busy": "2025-06-02T08:42:35.699297Z",
     "iopub.status.idle": "2025-06-02T08:42:35.717970Z",
     "shell.execute_reply": "2025-06-02T08:42:35.717589Z",
     "shell.execute_reply.started": "2025-06-02T08:42:35.699548Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory allocated: 15.26 GB\n",
      "GPU memory reserved: 15.28 GB\n"
     ]
    }
   ],
   "source": [
    "# 打印初始显存使用情况\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU memory allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"GPU memory reserved: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")\n",
    "\n",
    "# 2. 构造提示函数\n",
    "def create_zero_shot_prompt(passage: str, number: str) -> str:\n",
    "    \"\"\"构造零样本提示\"\"\"\n",
    "    return f\"\"\"### ROLE. You are an expert fact-checker specializing in numerical accuracy across biology, physics, history, mathematics, and everyday scenarios. ### TASK. Determine if the given number contains a factual error within the provided context. ### ANALYSIS PROCESS. Follow this reasoning sequence: 1. CONTEXT ANALYSIS: Identify the domain and type of measurement being described 2. GENERATED KNOWLEDGE: Recall established facts, typical ranges, and known standards for this specific domain and measurement type 3. PLAUSIBILITY CHECK: Compare the number against expected ranges, physical laws, biological constraints, historical accuracy, and mathematical consistency 4. ERROR DETECTION: Check for biological impossibilities, physical violations, historical inaccuracies, mathematical contradictions, or scale/magnitude errors. ### OUTPUT. Answer must only be \"Yes\" or \"No\",do not provide explanations. Yes = Contains factual error, No = Factually accurate. ### EVALUATION. Number to evaluate: \"{number}\",Passage: \"{passage}\". Is \"{number}\" in the following passage an error? \"{passage}\"\n",
    "Answer:\"\"\"\n",
    "\n",
    "def create_few_shot_prompt(passage: str, number: str) -> str:\n",
    "    \"\"\"构造少样本提示，包含示例\"\"\"\n",
    "    examples = [\n",
    "        {\n",
    "            \"passage\": \"Spiders have 9 limbs.\",\n",
    "            \"number\": \"9\",\n",
    "            \"answer\": \"Yes\"\n",
    "        },\n",
    "        {\n",
    "            \"passage\": \"Spiders have 8 limbs.\",\n",
    "            \"number\": \"8\",\n",
    "            \"answer\": \"No\"\n",
    "        },\n",
    "        {\n",
    "            \"passage\": \"Mike's height is -3.6 meters.\",\n",
    "            \"number\": \"-3.6\",\n",
    "            \"answer\": \"Yes\"\n",
    "        },\n",
    "        {\n",
    "            \"passage\": \"Mike's height is 1.8 meters.\",\n",
    "            \"number\": \"1.8\",\n",
    "            \"answer\": \"No\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    prompt = f\"\"\"### ROLE. You are an expert fact-checker specializing in numerical accuracy across biology, physics, history, mathematics, and everyday scenarios. ### TASK. Determine if the given number contains a factual error within the provided context. ### ANALYSIS PROCESS. Follow this reasoning sequence: 1. CONTEXT ANALYSIS: Identify the domain and type of measurement being described 2. GENERATED KNOWLEDGE: Recall established facts, typical ranges, and known standards for this specific domain and measurement type 3. PLAUSIBILITY CHECK: Compare the number against expected ranges, physical laws, biological constraints, historical accuracy, and mathematical consistency 4. ERROR DETECTION: Check for biological impossibilities, physical violations, historical inaccuracies, mathematical contradictions, or scale/magnitude errors. ### OUTPUT. Answer must only be \"Yes\" or \"No\",do not provide explanations. Yes = Contains factual error, No = Factually accurate.\"\"\"\n",
    "    for ex in examples:\n",
    "        prompt += f\"\"\"Question: Is \"{ex['number']}\" in the following passage an error? \"{ex['passage']}\"\n",
    "Answer: {ex['answer']}\\n\"\"\"\n",
    "    prompt += f\"\"\"Question: Is \"{number}\" in the following passage an error? \"{passage}\"\n",
    "Answer:\"\"\"\n",
    "    return prompt\n",
    "\n",
    "# 3. 加载 BeNEDect 数据集\n",
    "def load_benedect_dataset(file_path: str) -> List[Dict]:\n",
    "    \"\"\"加载数据集，返回包含提示和预期答案的样本列表\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"数据集文件 {file_path} 不存在，请确认路径！\")\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            dataset_dict = json.load(f)\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(f\"JSON 文件解析错误：{e}\")\n",
    "    \n",
    "    dataset = list(dataset_dict.values())\n",
    "    save_list = []\n",
    "    \n",
    "    for i, data in enumerate(tqdm(dataset, desc=\"Processing dataset\")):\n",
    "        required_fields = ['correct_number', 'correct_passage', 'error_number', 'error_passage', 'dataset', 'operation']\n",
    "        for field in required_fields:\n",
    "            if field not in data:\n",
    "                print(f\"样本 {data.get('id', '未知')} 缺少字段 {field}\")\n",
    "                continue\n",
    "        \n",
    "        prompt_fn = create_few_shot_prompt if i % 48 == 0 else create_zero_shot_prompt\n",
    "        \n",
    "        correct_item = {\n",
    "            \"prompt\": prompt_fn(data['correct_passage'], data['correct_number']),\n",
    "            \"expected_answer\": \"No\",\n",
    "            \"dataset\": data['dataset'],\n",
    "            \"operation\": data['operation'],\n",
    "            \"error_annotation\": data.get('error_annotation', {}),\n",
    "            \"passage\": data['correct_passage'],\n",
    "            \"number\": data['correct_number'],\n",
    "            \"prompt_type\": \"few_shot\" if i % 48 == 0 else \"zero_shot\"\n",
    "        }\n",
    "        \n",
    "        error_item = {\n",
    "            \"prompt\": prompt_fn(data['error_passage'], data['error_number']),\n",
    "            \"expected_answer\": \"Yes\",\n",
    "            \"dataset\": data['dataset'],\n",
    "            \"operation\": data['operation'],\n",
    "            \"error_annotation\": data.get('error_annotation', {}),\n",
    "            \"passage\": data['error_passage'],\n",
    "            \"number\": data['error_number'],\n",
    "            \"prompt_type\": \"few_shot\" if i % 48 == 0 else \"zero_shot\"\n",
    "        }\n",
    "        \n",
    "        save_list.append(correct_item)\n",
    "        save_list.append(error_item)\n",
    "    \n",
    "    return save_list\n",
    "\n",
    "# 4. 单条推理\n",
    "def predict_single(prompt: str, max_retries: int = 3) -> str:\n",
    "    \"\"\"对单个提示进行推理，包含重试机制和显存管理\"\"\"\n",
    "    print(f\"Single prediction prompt: {prompt[:100]}...\")  # 打印提示前 100 字符\n",
    "    attempt = 0\n",
    "    success = False\n",
    "    prediction = None\n",
    "    \n",
    "    while attempt < max_retries and not success:\n",
    "        try:\n",
    "            inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "            # 强制所有张量到 device\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            print(f\"Input device: {inputs['input_ids'].device}\")\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=5,  # 减小以确保简洁输出\n",
    "                    pad_token_id=tokenizer.pad_token_id,\n",
    "                    eos_token_id=tokenizer.eos_token_id,\n",
    "                    do_sample=True,\n",
    "                    temperature=0.3,\n",
    "                    top_p=0.5\n",
    "                )\n",
    "            \n",
    "            prediction = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True).strip()\n",
    "            success = True\n",
    "            print(f\"Single prediction success: Raw Prediction: {prediction}\")\n",
    "            \n",
    "        except RuntimeError as e:\n",
    "            print(f\"单条推理失败（尝试 {attempt + 1}/{max_retries}）：{e}\")\n",
    "            attempt += 1\n",
    "            torch.cuda.empty_cache()\n",
    "            time.sleep(1)\n",
    "            if attempt == max_retries:\n",
    "                print(\"单条推理失败，跳过\")\n",
    "                prediction = \"generation_error\"\n",
    "        \n",
    "        finally:\n",
    "            if 'inputs' in locals():\n",
    "                for v in inputs.values():\n",
    "                    del v\n",
    "            torch.cuda.empty_cache()\n",
    "            print(f\"GPU memory after single prediction: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# 5. 批次推理\n",
    "def predict_batch(prompts: List[str], batch_size: int = 8, max_retries: int = 3) -> List[str]:\n",
    "    \"\"\"按批次进行模型预测，包含重试和显存管理\"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(prompts), batch_size), desc=\"Predicting\"):\n",
    "        batch_prompts = prompts[i:i + batch_size]\n",
    "        attempt = 0\n",
    "        success = False\n",
    "        batch_preds = None\n",
    "        \n",
    "        while attempt < max_retries and not success:\n",
    "            try:\n",
    "                inputs = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "                # 强制所有张量到 device\n",
    "                inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    outputs = model.generate(\n",
    "                        **inputs,\n",
    "                        max_new_tokens=5,  # 减小以确保简洁输出\n",
    "                        pad_token_id=tokenizer.pad_token_id,\n",
    "                        eos_token_id=tokenizer.eos_token_id,\n",
    "                        do_sample=True,\n",
    "                        temperature=0.3,\n",
    "                        top_p=0.5\n",
    "                    )\n",
    "                \n",
    "                batch_preds = [\n",
    "                    tokenizer.decode(output[inputs['input_ids'].shape[1]:], skip_special_tokens=True).strip()\n",
    "                    for output in outputs\n",
    "                ]\n",
    "                success = True\n",
    "                \n",
    "                # 每 10 批次打印日志\n",
    "                if i % (10 * batch_size) == 0:\n",
    "                    print(f\"批次 {i//batch_size}: 原始预测: {batch_preds}\")\n",
    "                \n",
    "            except RuntimeError as e:\n",
    "                print(f\"批次推理失败（尝试 {attempt + 1}/{max_retries}）：{e}\")\n",
    "                attempt += 1\n",
    "                torch.cuda.empty_cache()\n",
    "                time.sleep(1)\n",
    "                if attempt == max_retries:\n",
    "                    print(f\"批次 {i//batch_size} 推理失败，跳过\")\n",
    "                    batch_preds = [\"generation_error\"] * len(batch_prompts)\n",
    "            \n",
    "            finally:\n",
    "                if 'inputs' in locals():\n",
    "                    for v in inputs.values():\n",
    "                        del v\n",
    "                torch.cuda.empty_cache()\n",
    "                print(f\"GPU memory after batch {i//batch_size}: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "        \n",
    "        predictions.extend(batch_preds)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# 6. 保存预测结果到 JSONL\n",
    "def save_predictions_to_jsonl(data: List[Dict], predictions: List[str], output_file: str):\n",
    "    \"\"\"将原始预测结果保存到 JSONL 文件\"\"\"\n",
    "    with jsonlines.open(output_file, mode='w') as writer:\n",
    "        for item, pred in zip(data, predictions):\n",
    "            result = {\n",
    "                \"prompt\": item['prompt'],\n",
    "                \"passage\": item['passage'],\n",
    "                \"number\": item['number'],\n",
    "                \"expected_answer\": item['expected_answer'],\n",
    "                \"raw_prediction\": pred,  # 直接保存原始预测\n",
    "                \"dataset\": item['dataset'],\n",
    "                \"operation\": item['operation'],\n",
    "                \"error_annotation\": item['error_annotation'],\n",
    "                \"prompt_type\": item['prompt_type']\n",
    "            }\n",
    "            writer.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-06-04T11:14:48.213427Z",
     "iopub.status.busy": "2025-06-04T11:14:48.213022Z",
     "iopub.status.idle": "2025-06-04T11:14:48.235815Z",
     "shell.execute_reply": "2025-06-04T11:14:48.235200Z",
     "shell.execute_reply.started": "2025-06-04T11:14:48.213410Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory allocated: 15.26 GB\n",
      "GPU memory reserved: 15.26 GB\n"
     ]
    }
   ],
   "source": [
    "#deepseek edit\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU memory allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"GPU memory reserved: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def create_zero_shot_prompt(passage: str, number: str) -> str:\n",
    "    return f\"\"\"### ROLE. You are an expert fact-checker specializing in numerical accuracy across biology, physics, history, mathematics, and everyday scenarios. ### TASK. Determine if the given number contains a factual error within the provided context. ### ANALYSIS PROCESS. Follow this reasoning sequence: 1. CONTEXT ANALYSIS: Identify the domain and type of measurement being described 2. GENERATED KNOWLEDGE: Recall established facts, typical ranges, and known standards for this specific domain and measurement type 3. PLAUSIBILITY CHECK: Compare the number against expected ranges, physical laws, biological constraints, historical accuracy, and mathematical consistency 4. ERROR DETECTION: Check for biological impossibilities, physical violations, historical inaccuracies, mathematical contradictions, or scale/magnitude errors. ### OUTPUT FORMAT. Answer must only be \"yes\" or \"no\". Do not provide any any explanations. ### EVALUATION. Is \"{number}\" in the following passage an error? \"{passage}\"?\n",
    "Answer:\"\"\"\n",
    "\n",
    "def create_few_shot_prompt(passage: str, number: str) -> str:\n",
    "    examples = [\n",
    "        {\"passage\": \"Spiders have 9 limbs.\", \"number\": \"9\", \"answer\": \"Yes\"},\n",
    "        {\"passage\": \"Spiders have 8 limbs.\", \"number\": \"8\", \"answer\": \"No\"},\n",
    "        {\"passage\": \"Mike's height is -3.6 meters.\", \"number\": \"-3.6\", \"answer\": \"Yes\"},\n",
    "        {\"passage\": \"Mike's height is 1.8 meters.\", \"number\": \"1.8\", \"answer\": \"No\"}\n",
    "    ]\n",
    "    prompt = f\"\"\"### ROLE. You are an expert fact-checker specializing in numerical accuracy across biology, physics, history, mathematics, and everyday scenarios. ### TASK. Determine if the given number contains a factual error within the provided context. ### ANALYSIS PROCESS. Follow this reasoning sequence: 1. CONTEXT ANALYSIS: Identify the domain and type of measurement being described 2. GENERATED KNOWLEDGE: Recall established facts, typical ranges, and known standards for this specific domain and measurement type 3. PLAUSIBILITY CHECK: Compare the number against expected ranges, physical laws, biological constraints, historical accuracy, and mathematical consistency 4. ERROR DETECTION: Check for biological impossibilities, physical violations, historical inaccuracies, mathematical contradictions, or scale/magnitude errors. ### OUTPUT FORMAT. Answer must only be \"Yes\" or \"No\". Do not provide any explanations. ### EVALUATION. Is \"{number}\" in the following passage an error? \"{passage}\"?\n",
    "Answer:\"\"\"\n",
    "    for ex in examples:\n",
    "        prompt += f\"\"\"Question: Is \"{ex['number']}\" in the following passage an error? \"{ex['passage']}\"\n",
    "Answer: {ex['answer']}\\n\"\"\"\n",
    "    prompt += f\"\"\"Question: Is \"{number}\" in the following passage an error? \"{passage}\"\n",
    "Answer:\"\"\"\n",
    "    return prompt\n",
    "\n",
    "# 3. 加载 BeNEDect 数据集\n",
    "def load_benedect_dataset(file_path: str) -> List[Dict]:\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"数据集文件 {file_path} 不存在，请确认路径！\")\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            dataset_dict = json.load(f)\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(f\"JSON 文件解析错误：{e}\")\n",
    "    \n",
    "    dataset = list(dataset_dict.values())\n",
    "    #dataset = dataset[:len(dataset) // 2]#!!!\n",
    "    save_list = []\n",
    "    \n",
    "    for i, data in enumerate(tqdm(dataset, desc=\"Processing dataset\")):\n",
    "        required_fields = ['correct_number', 'correct_passage', 'error_number', 'error_passage', 'dataset', 'operation']\n",
    "        for field in required_fields:\n",
    "            if field not in data:\n",
    "                print(f\"样本 {data.get('id', '未知')} 缺少字段 {field}\")\n",
    "                continue\n",
    "        \n",
    "        prompt_fn = create_few_shot_prompt if i % 48 == 0 else create_zero_shot_prompt\n",
    "        correct_item = {\n",
    "            \"prompt\": prompt_fn(data['correct_passage'], data['correct_number']),\n",
    "            \"expected_answer\": \"No\",\n",
    "            \"dataset\": data['dataset'],\n",
    "            \"operation\": data['operation'],\n",
    "            \"error_annotation\": data.get('error_annotation', {}),\n",
    "            \"passage\": data['correct_passage'],\n",
    "            \"number\": data['correct_number'],\n",
    "            \"prompt_type\": \"few_shot\" if i % 48 == 0 else \"zero_shot\"\n",
    "        }\n",
    "        error_item = {\n",
    "            \"prompt\": prompt_fn(data['error_passage'], data['error_number']),\n",
    "            \"expected_answer\": \"Yes\",\n",
    "            \"dataset\": data['dataset'],\n",
    "            \"operation\": data['operation'],\n",
    "            \"error_annotation\": data.get('error_annotation', {}),\n",
    "            \"passage\": data['error_passage'],\n",
    "            \"number\": data['error_number'],\n",
    "            \"prompt_type\": \"few_shot\" if i % 48 == 0 else \"zero_shot\"\n",
    "        }\n",
    "        save_list.append(correct_item)\n",
    "        save_list.append(error_item)\n",
    "    \n",
    "    return save_list\n",
    "\n",
    "    \n",
    "def majority_vote(responses: List[str]) -> str:\n",
    "    \"\"\"Determine majority vote from 3 responses (Yes/No)\"\"\"\n",
    "    valid_responses = []\n",
    "    for r in responses:\n",
    "        r_low = r.lower().strip()\n",
    "        if r_low.startswith('y') or r_low == 'yes':\n",
    "            valid_responses.append(\"Yes\")\n",
    "        elif r_low.startswith('n') or r_low == 'no':\n",
    "            valid_responses.append(\"No\")\n",
    "    \n",
    "    if not valid_responses:\n",
    "        first = responses[0].lower().strip()\n",
    "        if first.startswith('y') or first == 'yes':\n",
    "            return \"Yes\"\n",
    "        else:\n",
    "            return \"No\"  # Default to No\n",
    "    \n",
    "    count_yes = valid_responses.count(\"Yes\")\n",
    "    count_no = valid_responses.count(\"No\")\n",
    "    \n",
    "    if count_yes > count_no:\n",
    "        return \"Yes\"\n",
    "    elif count_no > count_yes:\n",
    "        return \"No\"\n",
    "    else:\n",
    "        return valid_responses[0]  # Tie-breaker: first valid response\n",
    "\n",
    "def predict_single(prompt: str, max_retries: int = 3) -> str:\n",
    "    print(f\"Single prediction prompt: {prompt[:100]}...\")\n",
    "    attempt = 0\n",
    "    success = False\n",
    "    prediction = None\n",
    "    \n",
    "    while attempt < max_retries and not success:\n",
    "        try:\n",
    "            inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # Generate 3 sequences for voting\n",
    "                outputs = model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=5,\n",
    "                    pad_token_id=tokenizer.pad_token_id,\n",
    "                    eos_token_id=tokenizer.eos_token_id,\n",
    "                    do_sample=True,\n",
    "                    temperature=0.3,\n",
    "                    top_p=0.5,\n",
    "                    num_return_sequences=3  # Key change: get 3 responses\n",
    "                )\n",
    "            \n",
    "            # Decode all 3 responses\n",
    "            responses = []\n",
    "            input_length = inputs['input_ids'].shape[1]\n",
    "            for i in range(3):\n",
    "                gen_tokens = outputs[i][input_length:]\n",
    "                responses.append(\n",
    "                    tokenizer.decode(gen_tokens, skip_special_tokens=True).strip()\n",
    "                )\n",
    "            \n",
    "            # Apply majority voting\n",
    "            prediction = majority_vote(responses)\n",
    "            success = True\n",
    "            \n",
    "        except RuntimeError as e:\n",
    "            print(f\"Retry {attempt+1}/{max_retries}: {e}\")\n",
    "            attempt += 1\n",
    "            torch.cuda.empty_cache()\n",
    "            time.sleep(1)\n",
    "            if attempt == max_retries:\n",
    "                prediction = \"generation_error\"\n",
    "        finally:\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "\n",
    "def predict_batch(prompts: List[str], batch_size: int = 4, max_retries: int = 3) -> List[str]:\n",
    "    predictions = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(prompts), batch_size), desc=\"Predicting\"):\n",
    "        batch_prompts = prompts[i:i + batch_size]\n",
    "        attempt = 0\n",
    "        success = False\n",
    "        batch_preds = [\"generation_error\"] * len(batch_prompts)  # Default\n",
    "        \n",
    "        while attempt < max_retries and not success:\n",
    "            try:\n",
    "                inputs = tokenizer(\n",
    "                    batch_prompts,\n",
    "                    return_tensors=\"pt\",\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    max_length=512\n",
    "                )\n",
    "                inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    # Generate 3 sequences per prompt\n",
    "                    outputs = model.generate(\n",
    "                        **inputs,\n",
    "                        max_new_tokens=5,\n",
    "                        pad_token_id=tokenizer.pad_token_id,\n",
    "                        eos_token_id=tokenizer.eos_token_id,\n",
    "                        do_sample=True,\n",
    "                        temperature=0.3,\n",
    "                        top_p=0.5,\n",
    "                        num_return_sequences=3  # Key change\n",
    "                    )\n",
    "                \n",
    "                # Process responses (batch_size * 3 sequences)\n",
    "                input_length = inputs['input_ids'].shape[1]\n",
    "                batch_preds = []\n",
    "                for j in range(len(batch_prompts)):\n",
    "                    responses = []\n",
    "                    for k in range(3):\n",
    "                        idx = j * 3 + k\n",
    "                        gen_tokens = outputs[idx][input_length:]\n",
    "                        responses.append(\n",
    "                            tokenizer.decode(gen_tokens, skip_special_tokens=True).strip()\n",
    "                        )\n",
    "                    batch_preds.append(majority_vote(responses))\n",
    "                \n",
    "                success = True\n",
    "                \n",
    "            except RuntimeError as e:\n",
    "                print(f\"Batch {i}-{i+batch_size} retry {attempt+1}/{max_retries}: {e}\")\n",
    "                attempt += 1\n",
    "                torch.cuda.empty_cache()\n",
    "                time.sleep(2)\n",
    "            finally:\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        predictions.extend(batch_preds)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# 6. 保存预测结果到 JSONL\n",
    "def save_predictions_to_jsonl(data: List[Dict], predictions: List[str], output_file: str):\n",
    "    \"\"\"将原始预测结果保存到 JSONL 文件\"\"\"\n",
    "    with jsonlines.open(output_file, mode='w') as writer:\n",
    "        for item, pred in zip(data, predictions):\n",
    "            result = {\n",
    "                \"prompt\": item['prompt'],\n",
    "                \"passage\": item['passage'],\n",
    "                \"number\": item['number'],\n",
    "                \"expected_answer\": item['expected_answer'],\n",
    "                \"raw_prediction\": pred,  # 直接保存原始预测\n",
    "                \"dataset\": item['dataset'],\n",
    "                \"operation\": item['operation'],\n",
    "                \"error_annotation\": item['error_annotation'],\n",
    "                \"prompt_type\": item['prompt_type']\n",
    "            }\n",
    "            writer.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-06-04T11:14:48.236550Z",
     "iopub.status.busy": "2025-06-04T11:14:48.236279Z",
     "iopub.status.idle": "2025-06-04T12:06:31.572434Z",
     "shell.execute_reply": "2025-06-04T12:06:31.571981Z",
     "shell.execute_reply.started": "2025-06-04T11:14:48.236534Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset: 100%|██████████| 4800/4800 [00:00<00:00, 260934.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 随机样本推理 ===\n",
      "Passage: Skirt Chaser 5K darts through Madison September 28\n",
      "Number: 28\n",
      "Expected Answer: No\n",
      "Prompt Type: zero_shot\n",
      "Prompt:\n",
      "### ROLE. You are an expert fact-checker specializing in numerical accuracy across biology, physics, history, mathematics, and everyday scenarios. ### TASK. Determine if the given number contains a factual error within the provided context. ### ANALYSIS PROCESS. Follow this reasoning sequence: 1. CONTEXT ANALYSIS: Identify the domain and type of measurement being described 2. GENERATED KNOWLEDGE: Recall established facts, typical ranges, and known standards for this specific domain and measurement type 3. PLAUSIBILITY CHECK: Compare the number against expected ranges, physical laws, biological constraints, historical accuracy, and mathematical consistency 4. ERROR DETECTION: Check for biological impossibilities, physical violations, historical inaccuracies, mathematical contradictions, or scale/magnitude errors. ### OUTPUT FORMAT. Answer must only be \"yes\" or \"no\". Do not provide any any explanations. ### EVALUATION. Is \"28\" in the following passage an error? \"Skirt Chaser 5K darts through Madison September 28\"?\n",
      "Answer:\n",
      "Single prediction prompt: ### ROLE. You are an expert fact-checker specializing in numerical accuracy across biology, physics,...\n",
      "Raw Prediction: No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 1200/1200 [51:41<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测结果已保存到 /mnt/workspace/model_eval_first/qwen_3_8b/qwen_3_predictions.jsonl\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/mnt/workspace/model_eval_first/BeNEDect_all.json\"  # 确认路径，必要时修改\n",
    "dataset = load_benedect_dataset(file_path)\n",
    "\n",
    "# 随机抽取一个样本进行单条推理\n",
    "random_sample = random.choice(dataset)\n",
    "print(\"=== 随机样本推理 ===\")\n",
    "print(f\"Passage: {random_sample['passage']}\")\n",
    "print(f\"Number: {random_sample['number']}\")\n",
    "print(f\"Expected Answer: {random_sample['expected_answer']}\")\n",
    "print(f\"Prompt Type: {random_sample['prompt_type']}\")\n",
    "print(f\"Prompt:\\n{random_sample['prompt']}\")\n",
    "\n",
    "random_pred = predict_single(random_sample['prompt'])\n",
    "print(f\"Raw Prediction: {random_pred}\")\n",
    "\n",
    "# 提取提示\n",
    "prompts = [item['prompt'] for item in dataset]\n",
    "\n",
    "# 进行批次推理\n",
    "predictions = predict_batch(prompts, batch_size=8, max_retries=3)\n",
    "\n",
    "# 保存预测结果到 JSONL\n",
    "output_file = \"/mnt/workspace/model_eval_first/qwen_3_8b/qwen_3_predictions.jsonl\"  # 确认路径，必要时修改\n",
    "save_predictions_to_jsonl(dataset, predictions, output_file)\n",
    "print(f\"预测结果已保存到 {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T12:06:46.078474Z",
     "iopub.status.busy": "2025-06-04T12:06:46.078175Z",
     "iopub.status.idle": "2025-06-04T12:06:46.081218Z",
     "shell.execute_reply": "2025-06-04T12:06:46.080790Z",
     "shell.execute_reply.started": "2025-06-04T12:06:46.078454Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T12:06:46.665815Z",
     "iopub.status.busy": "2025-06-04T12:06:46.665427Z",
     "iopub.status.idle": "2025-06-04T12:06:46.677740Z",
     "shell.execute_reply": "2025-06-04T12:06:46.677273Z",
     "shell.execute_reply.started": "2025-06-04T12:06:46.665792Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_prediction(raw_prediction: str) -> str:\n",
    "    raw_prediction = raw_prediction.lower()\n",
    "    if 'yes' in raw_prediction:\n",
    "        return 'yes'\n",
    "    elif 'no' in raw_prediction:\n",
    "        return 'no'\n",
    "    else:\n",
    "        # print(f\"无法解析响应: {raw_prediction}\")\n",
    "        return 'generation_error'\n",
    "\n",
    "def evaluate_model(data_list: List[Dict], unparsed_output_file: str = 'unparsed_predictions.json') -> Tuple[Dict, Dict]:\n",
    "    metrics = Counter()\n",
    "    detailed_metrics = {\n",
    "        'by_domain': defaultdict(Counter),\n",
    "        'by_error_type': defaultdict(Counter),\n",
    "        'by_operation': defaultdict(Counter),\n",
    "        'by_prompt_type': defaultdict(Counter)\n",
    "    }\n",
    "    unparsed_data = {}  # 存储无法解析的样本，格式为 {id: {...}}\n",
    "    \n",
    "    for idx, item in enumerate(data_list):\n",
    "        expected = item['expected_answer'].lower()  # Yes/No 转为小写\n",
    "        pred = parse_prediction(item['raw_prediction'])\n",
    "        item['parsel_prediction'] = pred  # 保存解析结果\n",
    "        \n",
    "        # 如果无法解析，添加到 unparsed_data\n",
    "        if pred == 'generation_error':\n",
    "            # 只保存 expected_answer == \"Yes\" 的样本（错误样本）\n",
    "            if expected == 'yes':\n",
    "                sample_id = f\"unparsed_{idx}\"\n",
    "                unparsed_data[sample_id] = {\n",
    "                    \"error_number\": item['number'],\n",
    "                    \"error_passage\": item['passage'],\n",
    "                    \"dataset\": item['dataset'],\n",
    "                    \"operation\": item['operation'],\n",
    "                    \"error_annotation\": item['error_annotation'],\n",
    "                    # 以下字段需补充（若有正确数据）\n",
    "                    \"correct_number\": \"\",  # 需手动补充或从原始数据推导\n",
    "                    \"correct_passage\": \"\"  # 需手动补充或从原始数据推导\n",
    "                }\n",
    "        \n",
    "        domain = item['dataset']\n",
    "        operation = item['operation']\n",
    "        prompt_type = item['prompt_type']\n",
    "        error_types = [k for k, v in item['error_annotation'].items() if v > 0]\n",
    "        \n",
    "        # 计算总体指标\n",
    "        if pred == expected:\n",
    "            if expected == 'yes':\n",
    "                metrics['TP'] += 1\n",
    "                for et in error_types:\n",
    "                    detailed_metrics['by_error_type'][et]['TP'] += 1\n",
    "                detailed_metrics['by_domain'][domain]['TP'] += 1\n",
    "                detailed_metrics['by_operation'][operation]['TP'] += 1\n",
    "                detailed_metrics['by_prompt_type'][prompt_type]['TP'] += 1\n",
    "            else:  # expected == 'no'\n",
    "                metrics['TN'] += 1\n",
    "                for et in error_types:\n",
    "                    detailed_metrics['by_error_type'][et]['TN'] += 1\n",
    "                detailed_metrics['by_domain'][domain]['TN'] += 1\n",
    "                detailed_metrics['by_operation'][operation]['TN'] += 1\n",
    "                detailed_metrics['by_prompt_type'][prompt_type]['TN'] += 1\n",
    "        else:\n",
    "            if expected == 'yes':\n",
    "                metrics['FN'] += 1\n",
    "                for et in error_types:\n",
    "                    detailed_metrics['by_error_type'][et]['FN'] += 1\n",
    "                detailed_metrics['by_domain'][domain]['FN'] += 1\n",
    "                detailed_metrics['by_operation'][operation]['FN'] += 1\n",
    "                detailed_metrics['by_prompt_type'][prompt_type]['FN'] += 1\n",
    "            else:  # expected == 'no'\n",
    "                metrics['FP'] += 1\n",
    "                for et in error_types:\n",
    "                    detailed_metrics['by_error_type'][et]['FP'] += 1\n",
    "                detailed_metrics['by_domain'][domain]['FP'] += 1\n",
    "                detailed_metrics['by_operation'][operation]['FP'] += 1\n",
    "                detailed_metrics['by_prompt_type'][prompt_type]['FP'] += 1\n",
    "        \n",
    "        if pred == 'generation_error':\n",
    "            metrics['Generation Error'] += 1\n",
    "            for et in error_types:\n",
    "                detailed_metrics['by_error_type'][et]['Generation Error'] += 1\n",
    "            detailed_metrics['by_domain'][domain]['Generation Error'] += 1\n",
    "            detailed_metrics['by_operation'][operation]['Generation Error'] += 1\n",
    "            detailed_metrics['by_prompt_type'][prompt_type]['Generation Error'] += 1\n",
    "    \n",
    "    # 保存无法解析的数据到 JSON\n",
    "    if unparsed_data:\n",
    "        with open(unparsed_output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(unparsed_data, f, indent=2, ensure_ascii=False)\n",
    "        # print(f\"无法解析的 {len(unparsed_data)} 条数据已保存到 {unparsed_output_file}\")\n",
    "        print(\"注意：JSON 文件仅包含 expected_answer='Yes' 的样本，correct_number 和 correct_passage 需手动补充\")\n",
    "    else:\n",
    "        print(\"没有无法解析的数据\")\n",
    "    \n",
    "    total = len(data_list)\n",
    "    metrics['Accuracy'] = (metrics['TP'] + metrics['TN']) / total if total > 0 else 0\n",
    "    return metrics, detailed_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T12:06:47.941385Z",
     "iopub.status.busy": "2025-06-04T12:06:47.940856Z",
     "iopub.status.idle": "2025-06-04T12:06:48.088117Z",
     "shell.execute_reply": "2025-06-04T12:06:48.087534Z",
     "shell.execute_reply.started": "2025-06-04T12:06:47.941363Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "没有无法解析的数据\n",
      "\n",
      "Overall Metrics:\n",
      "TN: 3033 (0.316)\n",
      "TP: 2464 (0.257)\n",
      "FN: 2336 (0.243)\n",
      "FP: 1767 (0.184)\n",
      "Accuracy: 0.573\n",
      "\n",
      "Metrics by Domain:\n",
      "Numeracy_600K_article_title: {'TN': 812, 'TP': 482, 'FN': 518, 'FP': 188}\n",
      "aclsent: {'FP': 496, 'TP': 644, 'TN': 452, 'FN': 304}\n",
      "DROP: {'FP': 371, 'TP': 403, 'TN': 623, 'FN': 591}\n",
      "qa-text-source-comparison: {'TN': 522, 'TP': 500, 'FP': 402, 'FN': 424}\n",
      "FinNum: {'FP': 310, 'FN': 499, 'TN': 624, 'TP': 435}\n",
      "\n",
      "Metrics by Error Type:\n",
      "Error in Number Relationships: {'TN': 103, 'TP': 117, 'FN': 79, 'FP': 93}\n",
      "Undetectable Error: {'TN': 277, 'FN': 264, 'FP': 187, 'TP': 200}\n",
      "Type Error: {'TN': 333, 'FN': 190, 'TP': 328, 'FP': 185}\n",
      "Anomaly: {'FP': 91, 'TP': 132, 'TN': 139, 'FN': 98}\n",
      "Improper Data: {'TN': 23, 'FN': 21, 'FP': 6, 'TP': 8}\n",
      "Factual Error: {'TN': 33, 'TP': 31, 'FP': 24, 'FN': 26}\n",
      "\n",
      "Metrics by Operation:\n",
      "*2: {'TN': 100, 'TP': 75, 'FP': 59, 'FN': 84}\n",
      "-10: {'TN': 125, 'FN': 92, 'TP': 91, 'FP': 58}\n",
      "+1: {'TN': 120, 'FN': 115, 'FP': 68, 'TP': 73}\n",
      "*0.9: {'TN': 120, 'FN': 92, 'TP': 94, 'FP': 66}\n",
      "*1.1: {'FP': 65, 'TP': 93, 'TN': 134, 'FN': 106}\n",
      "-0.5: {'TN': 93, 'FN': 67, 'TP': 89, 'FP': 63}\n",
      "+1000: {'TN': 99, 'TP': 92, 'FN': 67, 'FP': 60}\n",
      "*1.5: {'TN': 99, 'FN': 84, 'TP': 80, 'FP': 65}\n",
      "*0.1: {'TN': 96, 'FN': 69, 'FP': 65, 'TP': 92}\n",
      "*0: {'TN': 114, 'FN': 83, 'TP': 95, 'FP': 64}\n",
      "-0.1: {'TN': 111, 'FN': 85, 'TP': 103, 'FP': 77}\n",
      "swap: {'TN': 218, 'FN': 215, 'TP': 133, 'FP': 130}\n",
      "*0.01: {'TN': 113, 'TP': 101, 'FN': 80, 'FP': 68}\n",
      "+10: {'FP': 66, 'TP': 77, 'TN': 108, 'FN': 97}\n",
      "+0.1: {'TN': 111, 'TP': 75, 'FN': 88, 'FP': 52}\n",
      "*(-1): {'TN': 106, 'TP': 105, 'FN': 55, 'FP': 54}\n",
      "-1: {'TN': 128, 'FN': 122, 'FP': 72, 'TP': 78}\n",
      "*0.5: {'TN': 138, 'FN': 112, 'FP': 71, 'TP': 97}\n",
      "*100: {'TN': 97, 'TP': 91, 'FP': 64, 'FN': 70}\n",
      "+0.5: {'TN': 113, 'FN': 75, 'FP': 56, 'TP': 94}\n",
      "-1000: {'TN': 105, 'FN': 52, 'TP': 112, 'FP': 59}\n",
      "-100: {'TN': 104, 'FN': 63, 'FP': 51, 'TP': 92}\n",
      "*0.001: {'TN': 94, 'TP': 87, 'FN': 70, 'FP': 63}\n",
      "*0.7: {'TN': 85, 'FN': 74, 'TP': 55, 'FP': 44}\n",
      "*1000: {'TN': 98, 'FN': 62, 'FP': 73, 'TP': 109}\n",
      "+100: {'TN': 98, 'TP': 97, 'FP': 67, 'FN': 68}\n",
      "*10: {'TN': 106, 'FN': 89, 'TP': 84, 'FP': 67}\n",
      "\n",
      "Metrics by Prompt Type:\n",
      "few_shot: {'TN': 93, 'TP': 30, 'FN': 70, 'FP': 7}\n",
      "zero_shot: {'TN': 2940, 'FN': 2266, 'FP': 1760, 'TP': 2434}\n"
     ]
    }
   ],
   "source": [
    "# 读取 predictions.jsonl\n",
    "data_list = []\n",
    "input_file = 'qwen_3_predictions.jsonl'  # 确认路径\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        data_list.append(data)\n",
    "\n",
    "# 评测模型并保存无法解析的数据\n",
    "unparsed_output_file = 'qwen_3_unparsed_predictions.json'\n",
    "metrics, detailed_metrics = evaluate_model(data_list, unparsed_output_file)\n",
    "\n",
    "# 打印总体指标\n",
    "print(\"\\nOverall Metrics:\")\n",
    "total = len(data_list)\n",
    "for key, value in metrics.items():\n",
    "    if key == 'Accuracy':\n",
    "        print(f\"{key}: {value:.3f}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value} ({value / total:.3f})\")\n",
    "\n",
    "# 打印分维度指标\n",
    "print(\"\\nMetrics by Domain:\")\n",
    "for domain, counts in detailed_metrics['by_domain'].items():\n",
    "    print(f\"{domain}: {dict(counts)}\")\n",
    "\n",
    "print(\"\\nMetrics by Error Type:\")\n",
    "for error_type, counts in detailed_metrics['by_error_type'].items():\n",
    "    print(f\"{error_type}: {dict(counts)}\")\n",
    "\n",
    "print(\"\\nMetrics by Operation:\")\n",
    "for operation, counts in detailed_metrics['by_operation'].items():\n",
    "    print(f\"{operation}: {dict(counts)}\")\n",
    "\n",
    "print(\"\\nMetrics by Prompt Type:\")\n",
    "for prompt_type, counts in detailed_metrics['by_prompt_type'].items():\n",
    "    print(f\"{prompt_type}: {dict(counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7381062,
     "sourceId": 11757485,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
