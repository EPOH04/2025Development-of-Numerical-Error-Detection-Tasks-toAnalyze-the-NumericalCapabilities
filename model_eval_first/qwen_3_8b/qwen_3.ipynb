{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-10T09:37:27.098768Z",
     "iopub.status.busy": "2025-05-10T09:37:27.098532Z",
     "iopub.status.idle": "2025-05-10T09:37:31.040936Z",
     "shell.execute_reply": "2025-05-10T09:37:31.040010Z",
     "shell.execute_reply.started": "2025-05-10T09:37:27.098745Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jsonlines\n",
      "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines) (25.3.0)\n",
      "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Installing collected packages: jsonlines\n",
      "Successfully installed jsonlines-4.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T09:37:36.343368Z",
     "iopub.status.busy": "2025-05-10T09:37:36.342721Z",
     "iopub.status.idle": "2025-05-10T09:39:10.381327Z",
     "shell.execute_reply": "2025-05-10T09:39:10.380620Z",
     "shell.execute_reply.started": "2025-05-10T09:37:36.343344Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1cdf37a62924a83bd9d1ae31a0cbcca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/9.68k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b91fd5fb23a04e93b6948010a065e0fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12875287220242dc97b77bb49c99dccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85fa65687dc452497529c5cf68ab582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be24069dba8746fea0583be4e50c7a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/728 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 09:37:52.016328: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746869872.220107      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746869872.270811      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049c2b4357204b88a7ee3c34fa7896f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/32.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f4e6d8a703b462aab018cf42d9288bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e636a2716cd4406497370036724562db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00005.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5d8bf73f4924e6aaf241b8965e43e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00005.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d8be61dfbd4a988bcf9f1b737a9e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00005.safetensors:   0%|          | 0.00/3.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e2f8dcebeb4bd88a35c8d6796851ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00005.safetensors:   0%|          | 0.00/3.19G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59567ae2c7d4d26a2860e32d16f5a78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00005.safetensors:   0%|          | 0.00/1.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c56dec2374444b87b0a4217be675cffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6927154982474fcfa0cd247bd7a1bd66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-35): 36 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (down_proj): Linear(in_features=12288, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import List, Dict, Tuple\n",
    "import random\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "import time\n",
    "import logging\n",
    "import jsonlines\n",
    "\n",
    "# 设置日志\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1. 加载 Qwen3 模型和分词器\n",
    "model_name = \"Qwen/Qwen3-8B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.padding_side = 'left'\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.eval()  # 设置为评估模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T09:39:28.974210Z",
     "iopub.status.busy": "2025-05-10T09:39:28.973201Z",
     "iopub.status.idle": "2025-05-10T09:39:28.997424Z",
     "shell.execute_reply": "2025-05-10T09:39:28.996760Z",
     "shell.execute_reply.started": "2025-05-10T09:39:28.974185Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory allocated: 12.66 GB\n",
      "GPU memory reserved: 12.66 GB\n"
     ]
    }
   ],
   "source": [
    "# 打印初始显存使用情况\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU memory allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    print(f\"GPU memory reserved: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")\n",
    "\n",
    "# 2. 构造提示函数\n",
    "def create_zero_shot_prompt(passage: str, number: str) -> str:\n",
    "    \"\"\"构造零样本提示\"\"\"\n",
    "    return f\"\"\"Answer with only 'Yes' or 'No'. Do not provide explanations. Is \"{number}\" in the following passage an error? \"{passage}\"\n",
    "Answer:\"\"\"\n",
    "\n",
    "def create_few_shot_prompt(passage: str, number: str) -> str:\n",
    "    \"\"\"构造少样本提示，包含示例\"\"\"\n",
    "    examples = [\n",
    "        {\n",
    "            \"passage\": \"Spiders have 9 limbs.\",\n",
    "            \"number\": \"9\",\n",
    "            \"answer\": \"Yes\"\n",
    "        },\n",
    "        {\n",
    "            \"passage\": \"Spiders have 8 limbs.\",\n",
    "            \"number\": \"8\",\n",
    "            \"answer\": \"No\"\n",
    "        },\n",
    "        {\n",
    "            \"passage\": \"Mike's height is -3.6 meters.\",\n",
    "            \"number\": \"-3.6\",\n",
    "            \"answer\": \"Yes\"\n",
    "        },\n",
    "        {\n",
    "            \"passage\": \"Mike's height is 1.8 meters.\",\n",
    "            \"number\": \"1.8\",\n",
    "            \"answer\": \"No\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    prompt = \"Answer with only 'Yes' or 'No'. Do not provide explanations.\\n\"\n",
    "    for ex in examples:\n",
    "        prompt += f\"\"\"Question: Is \"{ex['number']}\" in the following passage an error? \"{ex['passage']}\"\n",
    "Answer: {ex['answer']}\\n\"\"\"\n",
    "    prompt += f\"\"\"Question: Is \"{number}\" in the following passage an error? \"{passage}\"\n",
    "Answer:\"\"\"\n",
    "    return prompt\n",
    "\n",
    "# 3. 加载 BeNEDect 数据集\n",
    "def load_benedect_dataset(file_path: str) -> List[Dict]:\n",
    "    \"\"\"加载数据集，返回包含提示和预期答案的样本列表\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"数据集文件 {file_path} 不存在，请确认路径！\")\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            dataset_dict = json.load(f)\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(f\"JSON 文件解析错误：{e}\")\n",
    "    \n",
    "    dataset = list(dataset_dict.values())\n",
    "    save_list = []\n",
    "    \n",
    "    for i, data in enumerate(tqdm(dataset, desc=\"Processing dataset\")):\n",
    "        required_fields = ['correct_number', 'correct_passage', 'error_number', 'error_passage', 'dataset', 'operation']\n",
    "        for field in required_fields:\n",
    "            if field not in data:\n",
    "                print(f\"样本 {data.get('id', '未知')} 缺少字段 {field}\")\n",
    "                continue\n",
    "        \n",
    "        prompt_fn = create_few_shot_prompt if i % 48 == 0 else create_zero_shot_prompt\n",
    "        \n",
    "        correct_item = {\n",
    "            \"prompt\": prompt_fn(data['correct_passage'], data['correct_number']),\n",
    "            \"expected_answer\": \"No\",\n",
    "            \"dataset\": data['dataset'],\n",
    "            \"operation\": data['operation'],\n",
    "            \"error_annotation\": data.get('error_annotation', {}),\n",
    "            \"passage\": data['correct_passage'],\n",
    "            \"number\": data['correct_number'],\n",
    "            \"prompt_type\": \"few_shot\" if i % 48 == 0 else \"zero_shot\"\n",
    "        }\n",
    "        \n",
    "        error_item = {\n",
    "            \"prompt\": prompt_fn(data['error_passage'], data['error_number']),\n",
    "            \"expected_answer\": \"Yes\",\n",
    "            \"dataset\": data['dataset'],\n",
    "            \"operation\": data['operation'],\n",
    "            \"error_annotation\": data.get('error_annotation', {}),\n",
    "            \"passage\": data['error_passage'],\n",
    "            \"number\": data['error_number'],\n",
    "            \"prompt_type\": \"few_shot\" if i % 48 == 0 else \"zero_shot\"\n",
    "        }\n",
    "        \n",
    "        save_list.append(correct_item)\n",
    "        save_list.append(error_item)\n",
    "    \n",
    "    return save_list\n",
    "\n",
    "# 4. 单条推理\n",
    "def predict_single(prompt: str, max_retries: int = 3) -> str:\n",
    "    \"\"\"对单个提示进行推理，包含重试机制和显存管理\"\"\"\n",
    "    print(f\"Single prediction prompt: {prompt[:100]}...\")  # 打印提示前 100 字符\n",
    "    attempt = 0\n",
    "    success = False\n",
    "    prediction = None\n",
    "    \n",
    "    while attempt < max_retries and not success:\n",
    "        try:\n",
    "            inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "            # 强制所有张量到 device\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            print(f\"Input device: {inputs['input_ids'].device}\")\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=5,  # 减小以确保简洁输出\n",
    "                    pad_token_id=tokenizer.pad_token_id,\n",
    "                    eos_token_id=tokenizer.eos_token_id,\n",
    "                    do_sample=False,  # 使用贪心解码\n",
    "                    top_k=1,\n",
    "                    top_p=0.0\n",
    "                )\n",
    "            \n",
    "            prediction = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True).strip()\n",
    "            success = True\n",
    "            print(f\"Single prediction success: Raw Prediction: {prediction}\")\n",
    "            \n",
    "        except RuntimeError as e:\n",
    "            print(f\"单条推理失败（尝试 {attempt + 1}/{max_retries}）：{e}\")\n",
    "            attempt += 1\n",
    "            torch.cuda.empty_cache()\n",
    "            time.sleep(1)\n",
    "            if attempt == max_retries:\n",
    "                print(\"单条推理失败，跳过\")\n",
    "                prediction = \"generation_error\"\n",
    "        \n",
    "        finally:\n",
    "            if 'inputs' in locals():\n",
    "                for v in inputs.values():\n",
    "                    del v\n",
    "            torch.cuda.empty_cache()\n",
    "            print(f\"GPU memory after single prediction: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# 5. 批次推理\n",
    "def predict_batch(prompts: List[str], batch_size: int = 8, max_retries: int = 3) -> List[str]:\n",
    "    \"\"\"按批次进行模型预测，包含重试和显存管理\"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(prompts), batch_size), desc=\"Predicting\"):\n",
    "        batch_prompts = prompts[i:i + batch_size]\n",
    "        attempt = 0\n",
    "        success = False\n",
    "        batch_preds = None\n",
    "        \n",
    "        while attempt < max_retries and not success:\n",
    "            try:\n",
    "                inputs = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "                # 强制所有张量到 device\n",
    "                inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    outputs = model.generate(\n",
    "                        **inputs,\n",
    "                        max_new_tokens=5,  # 减小以确保简洁输出\n",
    "                        pad_token_id=tokenizer.pad_token_id,\n",
    "                        eos_token_id=tokenizer.eos_token_id,\n",
    "                        do_sample=False,  # 使用贪心解码\n",
    "                        top_k=1,\n",
    "                        top_p=0.0\n",
    "                    )\n",
    "                \n",
    "                batch_preds = [\n",
    "                    tokenizer.decode(output[inputs['input_ids'].shape[1]:], skip_special_tokens=True).strip()\n",
    "                    for output in outputs\n",
    "                ]\n",
    "                success = True\n",
    "                \n",
    "                # 每 10 批次打印日志\n",
    "                if i % (10 * batch_size) == 0:\n",
    "                    print(f\"批次 {i//batch_size}: 原始预测: {batch_preds}\")\n",
    "                \n",
    "            except RuntimeError as e:\n",
    "                print(f\"批次推理失败（尝试 {attempt + 1}/{max_retries}）：{e}\")\n",
    "                attempt += 1\n",
    "                torch.cuda.empty_cache()\n",
    "                time.sleep(1)\n",
    "                if attempt == max_retries:\n",
    "                    print(f\"批次 {i//batch_size} 推理失败，跳过\")\n",
    "                    batch_preds = [\"generation_error\"] * len(batch_prompts)\n",
    "            \n",
    "            finally:\n",
    "                if 'inputs' in locals():\n",
    "                    for v in inputs.values():\n",
    "                        del v\n",
    "                torch.cuda.empty_cache()\n",
    "                print(f\"GPU memory after batch {i//batch_size}: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "        \n",
    "        predictions.extend(batch_preds)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# 6. 保存预测结果到 JSONL\n",
    "def save_predictions_to_jsonl(data: List[Dict], predictions: List[str], output_file: str):\n",
    "    \"\"\"将原始预测结果保存到 JSONL 文件\"\"\"\n",
    "    with jsonlines.open(output_file, mode='w') as writer:\n",
    "        for item, pred in zip(data, predictions):\n",
    "            result = {\n",
    "                \"prompt\": item['prompt'],\n",
    "                \"passage\": item['passage'],\n",
    "                \"number\": item['number'],\n",
    "                \"expected_answer\": item['expected_answer'],\n",
    "                \"raw_prediction\": pred,  # 直接保存原始预测\n",
    "                \"dataset\": item['dataset'],\n",
    "                \"operation\": item['operation'],\n",
    "                \"error_annotation\": item['error_annotation'],\n",
    "                \"prompt_type\": item['prompt_type']\n",
    "            }\n",
    "            writer.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T09:39:37.913672Z",
     "iopub.status.busy": "2025-05-10T09:39:37.912867Z",
     "iopub.status.idle": "2025-05-10T12:43:33.170412Z",
     "shell.execute_reply": "2025-05-10T12:43:33.169797Z",
     "shell.execute_reply.started": "2025-05-10T09:39:37.913615Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset: 100%|██████████| 4800/4800 [00:00<00:00, 228523.13it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:653: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 随机样本推理 ===\n",
      "Passage: By mid-1742, the War of the Austrian Succession had broken out in Europe. Principally fought by Prussia and Austria over possession of Silesia, the war soon engulfed most of the major powers of Europe, who joined two competing alliances. The scale of this new war dwarfed any of the fighting in the Americas, and drew Britain and Spain's attention back to operations on the European continent. The return of Vernon's fleet in 1742 marked the end of major offensive operations in the War of Jenkins' Ear. France entered the war in 1744.5, emphasizing the European theatre and planning an ambitious invasion of Britain. While it ultimately failed, the threat persuaded British policymakers of the dangers of sending significant forces to the Americas which might be needed at home. Britain did not attempt any additional attacks on Spanish possessions. In 1745, William Pepperrell of New England led a colonial expedition, supported by a British fleet under Commodore Peter Warren, against the French fortress of Louisbourg on Cape Breton Island off Canada. Pepperrell was knighted for his achievement, but Britain returned Louisbourg to the French by the Treaty of Aix-La-Chapelle in 1748. A decade later, during the Seven Years' War , British forces under Lord Jeffrey Amherst and General Wolfe recaptured it.\n",
      "Number: 1744.5\n",
      "Expected Answer: Yes\n",
      "Prompt Type: zero_shot\n",
      "Prompt:\n",
      "Answer with only 'Yes' or 'No'. Do not provide explanations. Is \"1744.5\" in the following passage an error? \"By mid-1742, the War of the Austrian Succession had broken out in Europe. Principally fought by Prussia and Austria over possession of Silesia, the war soon engulfed most of the major powers of Europe, who joined two competing alliances. The scale of this new war dwarfed any of the fighting in the Americas, and drew Britain and Spain's attention back to operations on the European continent. The return of Vernon's fleet in 1742 marked the end of major offensive operations in the War of Jenkins' Ear. France entered the war in 1744.5, emphasizing the European theatre and planning an ambitious invasion of Britain. While it ultimately failed, the threat persuaded British policymakers of the dangers of sending significant forces to the Americas which might be needed at home. Britain did not attempt any additional attacks on Spanish possessions. In 1745, William Pepperrell of New England led a colonial expedition, supported by a British fleet under Commodore Peter Warren, against the French fortress of Louisbourg on Cape Breton Island off Canada. Pepperrell was knighted for his achievement, but Britain returned Louisbourg to the French by the Treaty of Aix-La-Chapelle in 1748. A decade later, during the Seven Years' War , British forces under Lord Jeffrey Amherst and General Wolfe recaptured it.\"\n",
      "Answer:\n",
      "Single prediction prompt: Answer with only 'Yes' or 'No'. Do not provide explanations. Is \"1744.5\" in the following passage an...\n",
      "Input device: cuda:0\n",
      "Single prediction success: Raw Prediction: Yes. The date \"\n",
      "GPU memory after single prediction: 12.67 GB\n",
      "Raw Prediction: Yes. The date \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   0%|          | 1/1200 [00:07<2:37:42,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 0: 原始预测: ['Yes\\nQuestion: Is', 'Yes\\nQuestion: Is', 'Yes. Answer: Yes', 'Yes\\nAnswer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 0: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   0%|          | 2/1200 [00:13<2:15:58,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   0%|          | 3/1200 [00:19<2:06:21,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 2: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   0%|          | 4/1200 [00:25<2:03:57,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 3: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   0%|          | 5/1200 [00:31<2:02:51,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 4: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   0%|          | 6/1200 [00:37<1:59:58,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 5: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   1%|          | 7/1200 [00:43<1:59:59,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 6: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   1%|          | 8/1200 [00:49<1:59:41,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 7: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   1%|          | 9/1200 [00:55<1:58:03,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 8: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   1%|          | 10/1200 [01:01<1:58:30,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 9: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   1%|          | 11/1200 [01:07<1:58:58,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 10: 原始预测: ['Yes. The Surah', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 10: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   1%|          | 12/1200 [01:13<1:57:27,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 11: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   1%|          | 13/1200 [01:21<2:09:13,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 12: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   1%|          | 14/1200 [01:27<2:06:35,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 13: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   1%|▏         | 15/1200 [01:33<2:04:13,  6.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 14: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   1%|▏         | 16/1200 [01:39<2:01:09,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 15: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   1%|▏         | 17/1200 [01:44<1:58:48,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 16: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   2%|▏         | 18/1200 [01:50<1:58:51,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 17: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   2%|▏         | 19/1200 [01:56<1:57:16,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 18: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   2%|▏         | 20/1200 [02:02<1:56:01,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 19: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   2%|▏         | 21/1200 [02:08<1:56:48,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 20: 原始预测: ['Yes\\nAnswer: Yes', 'Yes\\nAnswer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The passage mentions']\n",
      "GPU memory after batch 20: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   2%|▏         | 22/1200 [02:14<1:56:24,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 21: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   2%|▏         | 23/1200 [02:20<1:56:26,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 22: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   2%|▏         | 24/1200 [02:26<1:56:57,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 23: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   2%|▏         | 25/1200 [02:34<2:09:37,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 24: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   2%|▏         | 26/1200 [02:40<2:06:10,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 25: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   2%|▏         | 27/1200 [02:46<2:01:47,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 26: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   2%|▏         | 28/1200 [02:52<2:00:51,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 27: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   2%|▏         | 29/1200 [02:58<1:58:23,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 28: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   2%|▎         | 30/1200 [03:03<1:56:28,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 29: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   3%|▎         | 31/1200 [03:09<1:56:39,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 30: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes\\nAnswer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 30: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   3%|▎         | 32/1200 [03:16<1:56:51,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 31: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   3%|▎         | 33/1200 [03:21<1:55:16,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 32: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   3%|▎         | 34/1200 [03:27<1:54:16,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 33: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   3%|▎         | 35/1200 [03:33<1:55:08,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 34: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   3%|▎         | 36/1200 [03:39<1:54:11,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 35: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   3%|▎         | 37/1200 [03:47<2:05:14,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 36: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   3%|▎         | 38/1200 [03:53<2:02:59,  6.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 37: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   3%|▎         | 39/1200 [03:59<2:01:08,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 38: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   3%|▎         | 40/1200 [04:05<1:58:18,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 39: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   3%|▎         | 41/1200 [04:10<1:56:10,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 40: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 40: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   4%|▎         | 42/1200 [04:16<1:54:47,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 41: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   4%|▎         | 43/1200 [04:22<1:54:15,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 42: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   4%|▎         | 44/1200 [04:28<1:54:54,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 43: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   4%|▍         | 45/1200 [04:34<1:55:19,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 44: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   4%|▍         | 46/1200 [04:40<1:53:55,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 45: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   4%|▍         | 47/1200 [04:46<1:54:34,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 46: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   4%|▍         | 48/1200 [04:52<1:53:14,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 47: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   4%|▍         | 49/1200 [05:00<2:04:41,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 48: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   4%|▍         | 50/1200 [05:06<2:02:58,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 49: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   4%|▍         | 51/1200 [05:12<2:00:22,  6.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 50: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The passage mentions', 'Yes. The date \"-']\n",
      "GPU memory after batch 50: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   4%|▍         | 52/1200 [05:18<1:57:22,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 51: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   4%|▍         | 53/1200 [05:23<1:55:47,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 52: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   4%|▍         | 54/1200 [05:29<1:55:18,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 53: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   5%|▍         | 55/1200 [05:36<1:55:17,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 54: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   5%|▍         | 56/1200 [05:41<1:53:37,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 55: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   5%|▍         | 57/1200 [05:47<1:52:27,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 56: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   5%|▍         | 58/1200 [05:53<1:51:32,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 57: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   5%|▍         | 59/1200 [05:59<1:50:51,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 58: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   5%|▌         | 60/1200 [06:05<1:51:32,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 59: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   5%|▌         | 61/1200 [06:12<2:02:50,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 60: 原始预测: ['No\\nQuestion: Is', 'Yes\\nQuestion: Is', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes\\nAnswer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 60: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   5%|▌         | 62/1200 [06:18<1:58:46,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 61: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   5%|▌         | 63/1200 [06:24<1:55:45,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 62: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   5%|▌         | 64/1200 [06:30<1:54:28,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 63: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   5%|▌         | 65/1200 [06:36<1:52:49,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 64: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   6%|▌         | 66/1200 [06:42<1:52:58,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 65: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   6%|▌         | 67/1200 [06:48<1:53:14,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 66: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   6%|▌         | 68/1200 [06:53<1:51:47,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 67: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   6%|▌         | 69/1200 [06:59<1:52:12,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 68: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   6%|▌         | 70/1200 [07:05<1:52:27,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 69: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   6%|▌         | 71/1200 [07:11<1:51:03,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 70: 原始预测: ['Yes. The number \"', 'Yes. Answer: Yes', 'Yes. The passage says', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The passage mentions', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 70: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   6%|▌         | 72/1200 [07:17<1:50:04,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 71: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   6%|▌         | 73/1200 [07:25<2:00:42,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 72: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   6%|▌         | 74/1200 [07:30<1:56:56,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 73: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   6%|▋         | 75/1200 [07:36<1:54:15,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 74: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   6%|▋         | 76/1200 [07:42<1:53:47,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 75: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   6%|▋         | 77/1200 [07:48<1:51:48,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 76: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   6%|▋         | 78/1200 [07:54<1:50:27,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 77: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   7%|▋         | 79/1200 [08:00<1:51:06,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 78: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   7%|▋         | 80/1200 [08:06<1:51:39,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 79: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   7%|▋         | 81/1200 [08:12<1:51:46,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 80: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes\\nAnswer: Yes', 'Yes\\nAnswer: Yes', 'Yes\\nAnswer: Yes', 'Yes\\n\\nAnswer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 80: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   7%|▋         | 82/1200 [08:18<1:50:18,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 81: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   7%|▋         | 83/1200 [08:24<1:50:47,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 82: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   7%|▋         | 84/1200 [08:30<1:51:05,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 83: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   7%|▋         | 85/1200 [08:38<2:01:31,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 84: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   7%|▋         | 86/1200 [08:43<1:57:11,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 85: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   7%|▋         | 87/1200 [08:49<1:55:28,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 86: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   7%|▋         | 88/1200 [08:55<1:53:52,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 87: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   7%|▋         | 89/1200 [09:01<1:53:11,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 88: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   8%|▊         | 90/1200 [09:07<1:51:54,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 89: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   8%|▊         | 91/1200 [09:13<1:50:14,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 90: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes\\n\\nAnswer: Yes', 'Yes. The number \"', 'Yes. The number \"', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 90: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   8%|▊         | 92/1200 [09:19<1:48:52,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 91: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   8%|▊         | 93/1200 [09:25<1:49:20,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 92: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   8%|▊         | 94/1200 [09:31<1:49:56,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 93: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   8%|▊         | 95/1200 [09:37<1:48:49,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 94: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   8%|▊         | 96/1200 [09:42<1:47:57,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 95: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   8%|▊         | 97/1200 [09:51<2:01:18,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 96: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   8%|▊         | 98/1200 [09:56<1:56:23,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 97: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   8%|▊         | 99/1200 [10:02<1:52:57,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 98: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   8%|▊         | 100/1200 [10:08<1:50:43,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 99: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   8%|▊         | 101/1200 [10:14<1:49:09,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 100: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 100: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   8%|▊         | 102/1200 [10:19<1:48:01,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 101: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   9%|▊         | 103/1200 [10:25<1:47:07,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 102: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   9%|▊         | 104/1200 [10:31<1:46:27,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 103: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   9%|▉         | 105/1200 [10:37<1:47:36,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 104: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   9%|▉         | 106/1200 [10:43<1:46:55,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 105: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   9%|▉         | 107/1200 [10:49<1:47:46,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 106: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   9%|▉         | 108/1200 [10:55<1:46:44,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 107: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   9%|▉         | 109/1200 [11:03<1:58:26,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 108: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   9%|▉         | 110/1200 [11:09<1:55:49,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 109: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   9%|▉         | 111/1200 [11:15<1:52:58,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 110: 原始预测: ['Yes\\n\\nAnswer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The passage contains', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 110: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   9%|▉         | 112/1200 [11:21<1:51:46,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 111: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   9%|▉         | 113/1200 [11:26<1:49:29,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 112: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  10%|▉         | 114/1200 [11:32<1:47:50,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 113: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  10%|▉         | 115/1200 [11:38<1:46:43,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 114: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  10%|▉         | 116/1200 [11:44<1:45:46,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 115: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  10%|▉         | 117/1200 [11:49<1:45:14,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 116: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  10%|▉         | 118/1200 [11:55<1:46:11,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 117: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  10%|▉         | 119/1200 [12:01<1:45:19,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 118: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  10%|█         | 120/1200 [12:07<1:46:12,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 119: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  10%|█         | 121/1200 [12:15<1:56:06,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 120: 原始预测: ['No\\nQuestion: Is', 'No\\nQuestion: Is', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes\\nAnswer: Yes', 'Yes\\nAnswer: Yes']\n",
      "GPU memory after batch 120: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  10%|█         | 122/1200 [12:21<1:52:19,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 121: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  10%|█         | 123/1200 [12:26<1:49:34,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 122: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  10%|█         | 124/1200 [12:32<1:47:23,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 123: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  10%|█         | 125/1200 [12:38<1:46:57,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 124: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  10%|█         | 126/1200 [12:44<1:45:42,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 125: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  11%|█         | 127/1200 [12:50<1:44:48,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 126: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  11%|█         | 128/1200 [12:55<1:44:11,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 127: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  11%|█         | 129/1200 [13:01<1:43:41,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 128: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  11%|█         | 130/1200 [13:07<1:43:21,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 129: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  11%|█         | 131/1200 [13:13<1:42:55,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 130: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The statement is', 'Yes. The passage states', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 130: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  11%|█         | 132/1200 [13:18<1:42:41,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 131: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  11%|█         | 133/1200 [13:26<1:54:38,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 132: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  11%|█         | 134/1200 [13:32<1:50:45,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 133: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  11%|█▏        | 135/1200 [13:38<1:48:08,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 134: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  11%|█▏        | 136/1200 [13:44<1:46:15,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 135: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  11%|█▏        | 137/1200 [13:49<1:44:57,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 136: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  12%|█▏        | 138/1200 [13:55<1:44:02,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 137: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  12%|█▏        | 139/1200 [14:01<1:43:12,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 138: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  12%|█▏        | 140/1200 [14:07<1:44:10,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 139: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  12%|█▏        | 141/1200 [14:13<1:43:15,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 140: 原始预测: ['Yes. The word \"', 'Yes. The number \"', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The passage states', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 140: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  12%|█▏        | 142/1200 [14:19<1:44:05,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 141: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  12%|█▏        | 143/1200 [14:25<1:44:43,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 142: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  12%|█▏        | 144/1200 [14:31<1:43:42,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 143: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  12%|█▏        | 145/1200 [14:38<1:54:07,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 144: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  12%|█▏        | 146/1200 [14:44<1:50:20,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 145: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  12%|█▏        | 147/1200 [14:50<1:47:24,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 146: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  12%|█▏        | 148/1200 [14:56<1:45:31,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 147: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  12%|█▏        | 149/1200 [15:02<1:44:04,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 148: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  12%|█▎        | 150/1200 [15:07<1:43:05,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 149: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  13%|█▎        | 151/1200 [15:13<1:43:53,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 150: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 150: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  13%|█▎        | 152/1200 [15:19<1:43:39,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 151: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  13%|█▎        | 153/1200 [15:25<1:44:20,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 152: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  13%|█▎        | 154/1200 [15:31<1:43:07,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 153: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  13%|█▎        | 155/1200 [15:37<1:43:40,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 154: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  13%|█▎        | 156/1200 [15:43<1:42:37,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 155: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  13%|█▎        | 157/1200 [15:51<1:52:33,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 156: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  13%|█▎        | 158/1200 [15:57<1:48:44,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 157: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  13%|█▎        | 159/1200 [16:03<1:47:26,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 158: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  13%|█▎        | 160/1200 [16:09<1:46:32,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 159: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  13%|█▎        | 161/1200 [16:14<1:44:14,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 160: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The number \"', 'Yes. The passage mentions', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes\\nAnswer: Yes']\n",
      "GPU memory after batch 160: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  14%|█▎        | 162/1200 [16:20<1:44:05,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 161: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  14%|█▎        | 163/1200 [16:26<1:42:49,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 162: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  14%|█▎        | 164/1200 [16:32<1:41:52,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 163: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  14%|█▍        | 165/1200 [16:38<1:41:01,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 164: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  14%|█▍        | 166/1200 [16:43<1:40:24,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 165: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  14%|█▍        | 167/1200 [16:49<1:39:56,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 166: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  14%|█▍        | 168/1200 [16:55<1:39:36,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 167: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  14%|█▍        | 169/1200 [17:03<1:50:08,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 168: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  14%|█▍        | 170/1200 [17:09<1:46:46,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 169: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  14%|█▍        | 171/1200 [17:14<1:44:19,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 170: 原始预测: ['Yes. The number \"', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The phrase \"', 'Yes. The phrase \"']\n",
      "GPU memory after batch 170: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  14%|█▍        | 172/1200 [17:20<1:42:31,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 171: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  14%|█▍        | 173/1200 [17:26<1:41:01,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 172: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  14%|█▍        | 174/1200 [17:32<1:41:39,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 173: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  15%|█▍        | 175/1200 [17:38<1:42:03,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 174: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  15%|█▍        | 176/1200 [17:44<1:42:18,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 175: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  15%|█▍        | 177/1200 [17:50<1:40:58,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 176: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  15%|█▍        | 178/1200 [17:56<1:41:05,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 177: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  15%|█▍        | 179/1200 [18:02<1:41:32,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 178: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  15%|█▌        | 180/1200 [18:08<1:41:48,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 179: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  15%|█▌        | 181/1200 [18:16<1:51:07,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 180: 原始预测: ['Yes\\nQuestion: Is', 'Yes\\nQuestion: Is', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 180: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  15%|█▌        | 182/1200 [18:21<1:46:58,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 181: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  15%|█▌        | 183/1200 [18:27<1:43:59,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 182: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  15%|█▌        | 184/1200 [18:33<1:41:59,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 183: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  15%|█▌        | 185/1200 [18:39<1:40:29,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 184: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  16%|█▌        | 186/1200 [18:45<1:40:51,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 185: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  16%|█▌        | 187/1200 [18:50<1:39:36,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 186: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  16%|█▌        | 188/1200 [18:56<1:39:48,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 187: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  16%|█▌        | 189/1200 [19:02<1:39:34,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 188: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  16%|█▌        | 190/1200 [19:08<1:38:48,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 189: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  16%|█▌        | 191/1200 [19:14<1:38:33,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 190: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 190: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  16%|█▌        | 192/1200 [19:20<1:37:59,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 191: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  16%|█▌        | 193/1200 [19:27<1:48:11,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 192: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  16%|█▌        | 194/1200 [19:33<1:46:00,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 193: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  16%|█▋        | 195/1200 [19:39<1:43:08,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 194: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  16%|█▋        | 196/1200 [19:45<1:42:19,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 195: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  16%|█▋        | 197/1200 [19:51<1:40:27,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 196: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  16%|█▋        | 198/1200 [19:57<1:39:06,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 197: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  17%|█▋        | 199/1200 [20:03<1:38:47,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 198: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  17%|█▋        | 200/1200 [20:08<1:37:58,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 199: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  17%|█▋        | 201/1200 [20:14<1:37:15,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 200: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The passage in', 'Yes. The passage \"', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 200: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  17%|█▋        | 202/1200 [20:20<1:38:06,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 201: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  17%|█▋        | 203/1200 [20:26<1:37:17,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 202: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  17%|█▋        | 204/1200 [20:32<1:36:39,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 203: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  17%|█▋        | 205/1200 [20:40<1:46:33,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 204: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  17%|█▋        | 206/1200 [20:45<1:43:06,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 205: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  17%|█▋        | 207/1200 [20:51<1:40:47,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 206: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  17%|█▋        | 208/1200 [20:57<1:39:02,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 207: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  17%|█▋        | 209/1200 [21:03<1:39:09,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 208: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  18%|█▊        | 210/1200 [21:09<1:37:47,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 209: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  18%|█▊        | 211/1200 [21:14<1:36:51,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 210: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 210: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  18%|█▊        | 212/1200 [21:20<1:37:25,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 211: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  18%|█▊        | 213/1200 [21:26<1:37:47,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 212: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  18%|█▊        | 214/1200 [21:32<1:36:33,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 213: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  18%|█▊        | 215/1200 [21:38<1:35:53,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 214: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  18%|█▊        | 216/1200 [21:44<1:35:30,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 215: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  18%|█▊        | 217/1200 [21:52<1:45:42,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 216: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  18%|█▊        | 218/1200 [21:58<1:43:34,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 217: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  18%|█▊        | 219/1200 [22:03<1:40:43,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 218: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  18%|█▊        | 220/1200 [22:09<1:40:00,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 219: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  18%|█▊        | 221/1200 [22:15<1:38:18,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 220: 原始预测: ['Yes. The \"Br', 'Yes. Answer: Yes', 'Yes. The passage states', 'Yes. The value \"', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 220: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  18%|█▊        | 222/1200 [22:21<1:38:18,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 221: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  19%|█▊        | 223/1200 [22:27<1:37:45,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 222: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  19%|█▊        | 224/1200 [22:33<1:37:55,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 223: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  19%|█▉        | 225/1200 [22:39<1:37:06,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 224: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  19%|█▉        | 226/1200 [22:45<1:37:30,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 225: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  19%|█▉        | 227/1200 [22:51<1:36:12,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 226: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  19%|█▉        | 228/1200 [22:57<1:35:06,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 227: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  19%|█▉        | 229/1200 [23:05<1:44:35,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 228: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  19%|█▉        | 230/1200 [23:11<1:42:27,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 229: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  19%|█▉        | 231/1200 [23:17<1:40:58,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 230: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The passage mentions', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The title \"', 'Yes. The number \"']\n",
      "GPU memory after batch 230: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  19%|█▉        | 232/1200 [23:23<1:39:50,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 231: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  19%|█▉        | 233/1200 [23:28<1:37:41,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 232: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  20%|█▉        | 234/1200 [23:34<1:36:27,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 233: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  20%|█▉        | 235/1200 [23:40<1:36:33,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 234: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  20%|█▉        | 236/1200 [23:46<1:36:12,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 235: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  20%|█▉        | 237/1200 [23:52<1:36:32,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 236: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  20%|█▉        | 238/1200 [23:58<1:36:10,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 237: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  20%|█▉        | 239/1200 [24:04<1:34:58,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 238: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  20%|██        | 240/1200 [24:10<1:35:23,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 239: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  20%|██        | 241/1200 [24:18<1:44:21,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 240: 原始预测: ['No\\nQuestion: Is', 'Yes\\nQuestion: Is', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 240: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  20%|██        | 242/1200 [24:24<1:41:35,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 241: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  20%|██        | 243/1200 [24:30<1:40:04,  6.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 242: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  20%|██        | 244/1200 [24:36<1:38:51,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 243: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  20%|██        | 245/1200 [24:42<1:37:53,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 244: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  20%|██        | 246/1200 [24:48<1:37:16,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 245: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  21%|██        | 247/1200 [24:54<1:36:04,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 246: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  21%|██        | 248/1200 [25:00<1:35:09,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 247: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  21%|██        | 249/1200 [25:06<1:35:19,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 248: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  21%|██        | 250/1200 [25:12<1:34:01,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 249: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  21%|██        | 251/1200 [25:18<1:35:55,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 250: 原始预测: ['Yes. The passage mentions', 'Yes. Answer: Yes', 'Yes. The mention of', 'Yes. The mention of', 'Yes. The number of', 'Yes. The passage states', 'Yes. The number', 'Yes. The number \"']\n",
      "GPU memory after batch 250: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  21%|██        | 252/1200 [25:25<1:38:04,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 251: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  21%|██        | 253/1200 [25:33<1:46:48,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 252: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  21%|██        | 254/1200 [25:39<1:46:26,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 253: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  21%|██▏       | 255/1200 [25:46<1:45:07,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 254: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  21%|██▏       | 256/1200 [25:53<1:45:04,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 255: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  21%|██▏       | 257/1200 [26:00<1:47:05,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 256: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  22%|██▏       | 258/1200 [26:07<1:48:55,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 257: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  22%|██▏       | 259/1200 [26:14<1:47:34,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 258: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  22%|██▏       | 260/1200 [26:21<1:50:57,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 259: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  22%|██▏       | 261/1200 [26:29<1:51:55,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 260: 原始预测: ['Yes. The passage states', 'Yes. Answer: Yes', 'Yes. The passage states', 'Yes. The passage states', 'Yes. The number \"', 'Yes. The number \"', 'No. The passage mentions', 'Yes\\nAnswer: Yes']\n",
      "GPU memory after batch 260: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  22%|██▏       | 262/1200 [26:36<1:54:44,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 261: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  22%|██▏       | 263/1200 [26:43<1:51:49,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 262: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  22%|██▏       | 264/1200 [26:51<1:55:10,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 263: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  22%|██▏       | 265/1200 [27:01<2:06:42,  8.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 264: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  22%|██▏       | 266/1200 [27:08<2:02:34,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 265: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  22%|██▏       | 267/1200 [27:15<1:56:39,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 266: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  22%|██▏       | 268/1200 [27:22<1:55:08,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 267: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  22%|██▏       | 269/1200 [27:30<1:56:44,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 268: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  22%|██▎       | 270/1200 [27:36<1:50:33,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 269: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  23%|██▎       | 271/1200 [27:44<1:55:29,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 270: 原始预测: ['Yes. Answer: Yes', 'Yes. The value \"', 'Yes. Answer: Yes', 'Yes. The value \"', 'Yes. The year \"', 'Yes. The year \"', 'Yes. The year \"', 'Yes. The year \"']\n",
      "GPU memory after batch 270: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  23%|██▎       | 272/1200 [27:51<1:52:17,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 271: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  23%|██▎       | 273/1200 [27:59<1:54:42,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 272: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  23%|██▎       | 274/1200 [28:06<1:55:43,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 273: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  23%|██▎       | 275/1200 [28:13<1:51:16,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 274: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  23%|██▎       | 276/1200 [28:21<1:54:23,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 275: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  23%|██▎       | 277/1200 [28:30<2:03:01,  8.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 276: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  23%|██▎       | 278/1200 [28:37<1:56:51,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 277: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  23%|██▎       | 279/1200 [28:44<1:52:52,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 278: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  23%|██▎       | 280/1200 [28:51<1:54:42,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 279: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  23%|██▎       | 281/1200 [28:59<1:53:32,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 280: 原始预测: ['Yes. The year \"', 'Yes. Answer: Yes', 'Yes. The passage states', 'Yes. The initial learning', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The passage mentions', 'Yes. The passage states']\n",
      "GPU memory after batch 280: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  24%|██▎       | 282/1200 [29:05<1:48:56,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 281: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  24%|██▎       | 283/1200 [29:12<1:48:44,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 282: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  24%|██▎       | 284/1200 [29:19<1:47:03,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 283: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  24%|██▍       | 285/1200 [29:27<1:51:15,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 284: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  24%|██▍       | 286/1200 [29:35<1:54:15,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 285: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  24%|██▍       | 287/1200 [29:42<1:50:15,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 286: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  24%|██▍       | 288/1200 [29:48<1:46:50,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 287: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  24%|██▍       | 289/1200 [29:58<2:00:42,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 288: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  24%|██▍       | 290/1200 [30:06<1:59:18,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 289: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  24%|██▍       | 291/1200 [30:12<1:51:34,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 290: 原始预测: ['Yes. The value \"', 'Yes. The weight decay', 'Yes. The passage mentions', 'Yes. The number \"', 'Yes. The number of', 'Yes. The beam size', 'Yes. The number \"', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 290: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  24%|██▍       | 292/1200 [30:19<1:49:44,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 291: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  24%|██▍       | 293/1200 [30:26<1:49:06,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 292: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  24%|██▍       | 294/1200 [30:33<1:46:31,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 293: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  25%|██▍       | 295/1200 [30:41<1:52:49,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 294: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  25%|██▍       | 296/1200 [30:48<1:51:03,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 295: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  25%|██▍       | 297/1200 [30:55<1:47:49,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 296: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  25%|██▍       | 298/1200 [31:02<1:46:00,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 297: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  25%|██▍       | 299/1200 [31:08<1:41:56,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 298: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  25%|██▌       | 300/1200 [31:15<1:43:27,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 299: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  25%|██▌       | 301/1200 [31:24<1:49:31,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 300: 原始预测: ['Yes\\nQuestion: Is', 'Yes\\nQuestion: Is', 'Yes. The bins are', 'Yes. The bin range', 'Yes. Answer: Yes', 'Yes. The batch size', 'Yes. The value \"', 'Yes. The value \"-']\n",
      "GPU memory after batch 300: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  25%|██▌       | 302/1200 [31:30<1:45:09,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 301: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  25%|██▌       | 303/1200 [31:37<1:47:08,  7.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 302: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  25%|██▌       | 304/1200 [31:45<1:47:40,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 303: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  25%|██▌       | 305/1200 [31:52<1:45:41,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 304: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  26%|██▌       | 306/1200 [31:58<1:41:20,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 305: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  26%|██▌       | 307/1200 [32:04<1:40:38,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 306: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  26%|██▌       | 308/1200 [32:11<1:40:15,  6.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 307: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  26%|██▌       | 309/1200 [32:19<1:45:04,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 308: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  26%|██▌       | 310/1200 [32:26<1:45:17,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 309: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  26%|██▌       | 311/1200 [32:34<1:46:54,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 310: 原始预测: ['Yes. Answer: Yes', 'Yes. The number \"', 'Yes. The number \"', 'Yes. The number \"', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 310: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  26%|██▌       | 312/1200 [32:41<1:47:40,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 311: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  26%|██▌       | 313/1200 [32:51<1:59:47,  8.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 312: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  26%|██▌       | 314/1200 [32:58<1:53:22,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 313: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  26%|██▋       | 315/1200 [33:05<1:52:33,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 314: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  26%|██▋       | 316/1200 [33:12<1:48:39,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 315: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  26%|██▋       | 317/1200 [33:20<1:50:16,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 316: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  26%|██▋       | 318/1200 [33:26<1:45:48,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 317: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  27%|██▋       | 319/1200 [33:34<1:48:34,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 318: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  27%|██▋       | 320/1200 [33:41<1:47:35,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 319: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  27%|██▋       | 321/1200 [33:48<1:46:21,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 320: 原始预测: ['Yes. The number \"', 'Yes. The value \"', 'Yes. The passage mentions', 'Yes. The passage mentions', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 320: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  27%|██▋       | 322/1200 [33:55<1:43:34,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 321: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  27%|██▋       | 323/1200 [34:02<1:43:33,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 322: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  27%|██▋       | 324/1200 [34:09<1:43:40,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 323: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  27%|██▋       | 325/1200 [34:18<1:51:23,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 324: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  27%|██▋       | 326/1200 [34:25<1:48:51,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 325: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  27%|██▋       | 327/1200 [34:33<1:48:20,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 326: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  27%|██▋       | 328/1200 [34:40<1:47:04,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 327: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  27%|██▋       | 329/1200 [34:46<1:43:53,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 328: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  28%|██▊       | 330/1200 [34:54<1:46:25,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 329: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  28%|██▊       | 331/1200 [35:01<1:45:15,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 330: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The passage states', 'Yes. Answer: Yes', 'Yes. The passage mentions', 'Yes. The passage mentions', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 330: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  28%|██▊       | 332/1200 [35:08<1:40:34,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 331: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  28%|██▊       | 333/1200 [35:14<1:39:44,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 332: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  28%|██▊       | 334/1200 [35:21<1:37:55,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 333: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  28%|██▊       | 335/1200 [35:28<1:37:14,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 334: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  28%|██▊       | 336/1200 [35:35<1:38:36,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 335: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  28%|██▊       | 337/1200 [35:45<1:52:17,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 336: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  28%|██▊       | 338/1200 [35:51<1:47:06,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 337: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  28%|██▊       | 339/1200 [35:58<1:43:48,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 338: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  28%|██▊       | 340/1200 [36:06<1:44:52,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 339: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  28%|██▊       | 341/1200 [36:12<1:41:54,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 340: 原始预测: ['No. The passage is', 'No. The passage is', 'Yes. The passage states', 'Yes. The percentage margin', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The passage contains', 'Yes. The passage mentions']\n",
      "GPU memory after batch 340: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  28%|██▊       | 342/1200 [36:20<1:44:55,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 341: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  29%|██▊       | 343/1200 [36:27<1:41:24,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 342: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  29%|██▊       | 344/1200 [36:34<1:41:12,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 343: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  29%|██▉       | 345/1200 [36:40<1:37:59,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 344: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  29%|██▉       | 346/1200 [36:47<1:37:26,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 345: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  29%|██▉       | 347/1200 [36:54<1:38:46,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 346: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  29%|██▉       | 348/1200 [37:01<1:39:49,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 347: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  29%|██▉       | 349/1200 [37:10<1:45:10,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 348: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  29%|██▉       | 350/1200 [37:17<1:45:38,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 349: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  29%|██▉       | 351/1200 [37:25<1:45:50,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 350: 原始预测: ['Yes. The numbers in', 'Yes. The value \"', 'Yes. The numbers in', 'Yes. The numbers in', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The passage states', 'Yes. The version number']\n",
      "GPU memory after batch 350: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  29%|██▉       | 352/1200 [37:32<1:46:59,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 351: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  29%|██▉       | 353/1200 [37:39<1:42:51,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 352: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  30%|██▉       | 354/1200 [37:46<1:39:53,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 353: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  30%|██▉       | 355/1200 [37:53<1:41:33,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 354: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  30%|██▉       | 356/1200 [38:01<1:43:48,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 355: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  30%|██▉       | 357/1200 [38:08<1:41:07,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 356: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  30%|██▉       | 358/1200 [38:15<1:42:14,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 357: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  30%|██▉       | 359/1200 [38:22<1:39:34,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 358: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  30%|███       | 360/1200 [38:29<1:41:16,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 359: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  30%|███       | 361/1200 [38:37<1:44:34,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 360: 原始预测: ['No\\nQuestion: Is', 'Yes\\nQuestion: Is', 'Yes. The passage states', 'Yes. The answer is', 'Yes. The year \"', 'Yes. The year \"', 'No. Answer: No', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 360: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  30%|███       | 362/1200 [38:44<1:41:04,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 361: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  30%|███       | 363/1200 [38:51<1:40:48,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 362: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  30%|███       | 364/1200 [38:58<1:40:18,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 363: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  30%|███       | 365/1200 [39:05<1:37:38,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 364: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  30%|███       | 366/1200 [39:13<1:41:13,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 365: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  31%|███       | 367/1200 [39:20<1:40:16,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 366: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  31%|███       | 368/1200 [39:27<1:38:20,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 367: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  31%|███       | 369/1200 [39:34<1:38:43,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 368: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  31%|███       | 370/1200 [39:41<1:38:56,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 369: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  31%|███       | 371/1200 [39:48<1:38:39,  7.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 370: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The passage states', 'Yes. The model described', 'Yes. The passage states', 'Yes. The passage states', 'Yes. The passage states', 'Yes. The passage states']\n",
      "GPU memory after batch 370: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  31%|███       | 372/1200 [39:55<1:37:02,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 371: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  31%|███       | 373/1200 [40:04<1:44:54,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 372: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  31%|███       | 374/1200 [40:10<1:39:47,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 373: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  31%|███▏      | 375/1200 [40:17<1:35:20,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 374: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  31%|███▏      | 376/1200 [40:24<1:36:26,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 375: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  31%|███▏      | 377/1200 [40:31<1:36:34,  7.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 376: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  32%|███▏      | 378/1200 [40:38<1:35:27,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 377: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  32%|███▏      | 379/1200 [40:44<1:33:03,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 378: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  32%|███▏      | 380/1200 [40:51<1:32:09,  6.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 379: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  32%|███▏      | 381/1200 [40:57<1:30:44,  6.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 380: 原始预测: ['Yes. The passage states', 'Yes. The date \"', 'Yes. The passage contains', 'Yes. The date \"', 'Yes. The date \"', 'Yes. The date \"', 'Yes. The passage contains', 'Yes. The date \"']\n",
      "GPU memory after batch 380: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  32%|███▏      | 382/1200 [41:04<1:30:16,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 381: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  32%|███▏      | 383/1200 [41:11<1:32:30,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 382: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  32%|███▏      | 384/1200 [41:18<1:34:00,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 383: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  32%|███▏      | 385/1200 [41:29<1:48:56,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 384: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  32%|███▏      | 386/1200 [41:36<1:43:42,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 385: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  32%|███▏      | 387/1200 [41:43<1:41:29,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 386: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  32%|███▏      | 388/1200 [41:49<1:36:45,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 387: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  32%|███▏      | 389/1200 [41:56<1:35:06,  7.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 388: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  32%|███▎      | 390/1200 [42:03<1:34:01,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 389: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  33%|███▎      | 391/1200 [42:10<1:34:49,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 390: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'No. The year \"', 'Yes. Answer: Yes', 'Yes. The \"1', 'Yes. Answer: Yes', 'Yes. The \"1', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 390: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  33%|███▎      | 392/1200 [42:17<1:36:38,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 391: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  33%|███▎      | 393/1200 [42:24<1:34:50,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 392: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  33%|███▎      | 394/1200 [42:31<1:35:26,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 393: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  33%|███▎      | 395/1200 [42:38<1:32:35,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 394: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  33%|███▎      | 396/1200 [42:44<1:31:22,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 395: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  33%|███▎      | 397/1200 [42:54<1:42:17,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 396: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  33%|███▎      | 398/1200 [43:01<1:38:07,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 397: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  33%|███▎      | 399/1200 [43:07<1:35:15,  7.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 398: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  33%|███▎      | 400/1200 [43:15<1:39:07,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 399: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  33%|███▎      | 401/1200 [43:22<1:35:18,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 400: 原始预测: ['Yes. The passage mentions', 'Yes. The number \"', 'Yes. The passage contains', 'Yes. The passage contains', 'Yes. The passage contains', 'Yes. The passage contains', 'Yes. The number \"', 'Yes. The number \"']\n",
      "GPU memory after batch 400: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  34%|███▎      | 402/1200 [43:29<1:36:47,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 401: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  34%|███▎      | 403/1200 [43:36<1:34:15,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 402: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  34%|███▎      | 404/1200 [43:45<1:40:43,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 403: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  34%|███▍      | 405/1200 [43:52<1:37:16,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 404: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  34%|███▍      | 406/1200 [43:58<1:34:32,  7.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 405: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  34%|███▍      | 407/1200 [44:05<1:32:34,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 406: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  34%|███▍      | 408/1200 [44:12<1:32:49,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 407: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  34%|███▍      | 409/1200 [44:20<1:38:20,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 408: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  34%|███▍      | 410/1200 [44:27<1:33:55,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 409: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  34%|███▍      | 411/1200 [44:34<1:35:19,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 410: 原始预测: ['Yes. The passage mentions', 'Yes. The passage mentions', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The number \"', 'Yes. The passage states', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 410: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  34%|███▍      | 412/1200 [44:41<1:32:55,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 411: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  34%|███▍      | 413/1200 [44:48<1:31:18,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 412: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  34%|███▍      | 414/1200 [44:54<1:30:19,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 413: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  35%|███▍      | 415/1200 [45:02<1:32:44,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 414: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  35%|███▍      | 416/1200 [45:08<1:29:59,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 415: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  35%|███▍      | 417/1200 [45:15<1:28:31,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 416: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  35%|███▍      | 418/1200 [45:22<1:29:55,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 417: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  35%|███▍      | 419/1200 [45:30<1:32:12,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 418: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  35%|███▌      | 420/1200 [45:36<1:30:27,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 419: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  35%|███▌      | 421/1200 [45:45<1:38:35,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 420: 原始预测: ['No\\nQuestion: Is', 'Yes\\nQuestion: Is', 'Yes. The number \"', 'Yes. The passage mentions', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The value \"', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 420: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  35%|███▌      | 422/1200 [45:52<1:34:49,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 421: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  35%|███▌      | 423/1200 [45:59<1:34:03,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 422: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  35%|███▌      | 424/1200 [46:06<1:31:39,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 423: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  35%|███▌      | 425/1200 [46:13<1:30:19,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 424: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  36%|███▌      | 426/1200 [46:20<1:31:28,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 425: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  36%|███▌      | 427/1200 [46:27<1:32:53,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 426: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  36%|███▌      | 428/1200 [46:35<1:32:29,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 427: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  36%|███▌      | 429/1200 [46:42<1:32:18,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 428: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  36%|███▌      | 430/1200 [46:49<1:32:24,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 429: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  36%|███▌      | 431/1200 [46:56<1:30:13,  7.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 430: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes\\n\\nAnswer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The passage states', 'Yes. The passage states']\n",
      "GPU memory after batch 430: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  36%|███▌      | 432/1200 [47:02<1:29:00,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 431: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  36%|███▌      | 433/1200 [47:11<1:34:35,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 432: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  36%|███▌      | 434/1200 [47:18<1:32:07,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 433: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  36%|███▋      | 435/1200 [47:24<1:29:17,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 434: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  36%|███▋      | 436/1200 [47:32<1:31:02,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 435: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  36%|███▋      | 437/1200 [47:39<1:31:14,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 436: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  36%|███▋      | 438/1200 [47:47<1:36:05,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 437: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  37%|███▋      | 439/1200 [47:54<1:32:42,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 438: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  37%|███▋      | 440/1200 [48:01<1:32:12,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 439: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  37%|███▋      | 441/1200 [48:08<1:31:29,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 440: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The passage states', 'Yes. The passage states', 'Yes. The value \"', 'Yes. The number \"', 'Yes. Answer: Yes', 'Yes\\nAnswer: Yes']\n",
      "GPU memory after batch 440: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  37%|███▋      | 442/1200 [48:15<1:27:27,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 441: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  37%|███▋      | 443/1200 [48:21<1:26:22,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 442: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  37%|███▋      | 444/1200 [48:28<1:27:35,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 443: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  37%|███▋      | 445/1200 [48:37<1:33:15,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 444: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  37%|███▋      | 446/1200 [48:44<1:30:39,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 445: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  37%|███▋      | 447/1200 [48:51<1:30:22,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 446: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  37%|███▋      | 448/1200 [48:58<1:31:29,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 447: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  37%|███▋      | 449/1200 [49:06<1:30:32,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 448: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  38%|███▊      | 450/1200 [49:12<1:28:48,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 449: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  38%|███▊      | 451/1200 [49:20<1:29:05,  7.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 450: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes\\nAnswer: Yes', 'Yes. Answer: Yes', 'Yes. The passage states', 'Yes. The passage mentions']\n",
      "GPU memory after batch 450: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  38%|███▊      | 452/1200 [49:27<1:28:56,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 451: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  38%|███▊      | 453/1200 [49:33<1:25:17,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 452: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  38%|███▊      | 454/1200 [49:39<1:23:31,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 453: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  38%|███▊      | 455/1200 [49:46<1:22:48,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 454: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  38%|███▊      | 456/1200 [49:53<1:23:07,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 455: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  38%|███▊      | 457/1200 [50:01<1:30:42,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 456: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  38%|███▊      | 458/1200 [50:08<1:28:37,  7.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 457: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  38%|███▊      | 459/1200 [50:15<1:28:42,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 458: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  38%|███▊      | 460/1200 [50:23<1:28:32,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 459: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  38%|███▊      | 461/1200 [50:30<1:29:35,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 460: 原始预测: ['Yes. The passage states', 'Yes. The passage states', 'Yes. The number \"', 'Yes. Answer: Yes', 'No. The year \"', 'Yes. The year \"-', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 460: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  38%|███▊      | 462/1200 [50:38<1:31:15,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 461: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  39%|███▊      | 463/1200 [50:45<1:31:27,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 462: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  39%|███▊      | 464/1200 [50:53<1:31:46,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 463: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  39%|███▉      | 465/1200 [51:00<1:29:05,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 464: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  39%|███▉      | 466/1200 [51:07<1:28:53,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 465: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  39%|███▉      | 467/1200 [51:13<1:25:23,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 466: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  39%|███▉      | 468/1200 [51:20<1:25:12,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 467: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  39%|███▉      | 469/1200 [51:29<1:30:37,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 468: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  39%|███▉      | 470/1200 [51:36<1:30:43,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 469: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  39%|███▉      | 471/1200 [51:43<1:29:43,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 470: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The numbers in', 'Yes. The numbers in', 'Yes. The passage mentions', 'Yes. The passage mentions', 'Yes. Answer: Yes', 'Yes. The passage states']\n",
      "GPU memory after batch 470: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  39%|███▉      | 472/1200 [51:51<1:28:35,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 471: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  39%|███▉      | 473/1200 [51:58<1:27:46,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 472: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  40%|███▉      | 474/1200 [52:05<1:28:47,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 473: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  40%|███▉      | 475/1200 [52:12<1:25:10,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 474: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  40%|███▉      | 476/1200 [52:19<1:27:40,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 475: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  40%|███▉      | 477/1200 [52:26<1:26:29,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 476: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  40%|███▉      | 478/1200 [52:34<1:26:35,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 477: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  40%|███▉      | 479/1200 [52:41<1:28:07,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 478: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  40%|████      | 480/1200 [52:48<1:25:11,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 479: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  40%|████      | 481/1200 [52:57<1:31:01,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 480: 原始预测: ['No\\nQuestion: Is', 'Yes\\nQuestion: Is', 'No. Answer: No', 'Yes. Answer: Yes', 'Yes. The passage mentions', 'Yes. Answer: Yes', 'No. Answer: No', 'Yes. The value']\n",
      "GPU memory after batch 480: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  40%|████      | 482/1200 [53:03<1:27:33,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 481: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  40%|████      | 483/1200 [53:11<1:29:44,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 482: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  40%|████      | 484/1200 [53:18<1:25:50,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 483: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  40%|████      | 485/1200 [53:24<1:23:30,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 484: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  40%|████      | 486/1200 [53:31<1:21:47,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 485: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  41%|████      | 487/1200 [53:37<1:20:58,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 486: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  41%|████      | 488/1200 [53:52<1:48:04,  9.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 487: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  41%|████      | 489/1200 [54:04<1:59:55, 10.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 488: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  41%|████      | 490/1200 [54:17<2:07:07, 10.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 489: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  41%|████      | 491/1200 [54:31<2:21:00, 11.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 490: 原始预测: ['Yes. The passage mentions', 'Yes. The date \"', 'Yes. The number \"', 'Yes. The date \"', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: No', 'Yes. Answer: No']\n",
      "GPU memory after batch 490: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  41%|████      | 492/1200 [54:45<2:27:01, 12.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 491: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  41%|████      | 493/1200 [54:57<2:25:54, 12.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 492: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  41%|████      | 494/1200 [55:12<2:34:52, 13.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 493: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  41%|████▏     | 495/1200 [55:27<2:39:09, 13.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 494: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  41%|████▏     | 496/1200 [55:38<2:32:47, 13.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 495: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  41%|████▏     | 497/1200 [55:51<2:29:39, 12.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 496: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  42%|████▏     | 498/1200 [56:05<2:33:41, 13.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 497: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  42%|████▏     | 499/1200 [56:17<2:32:09, 13.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 498: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  42%|████▏     | 500/1200 [56:31<2:33:07, 13.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 499: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  42%|████▏     | 501/1200 [56:45<2:35:59, 13.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 500: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The passage mentions', 'Yes. Answer: Yes', 'Yes. Answer: No', 'Yes. Answer: No', 'Yes. The passage mentions', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 500: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  42%|████▏     | 502/1200 [56:57<2:32:42, 13.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 501: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  42%|████▏     | 503/1200 [57:12<2:37:10, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 502: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  42%|████▏     | 504/1200 [57:27<2:41:58, 13.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 503: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  42%|████▏     | 505/1200 [57:41<2:44:00, 14.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 504: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  42%|████▏     | 506/1200 [57:54<2:39:30, 13.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 505: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  42%|████▏     | 507/1200 [58:08<2:38:40, 13.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 506: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  42%|████▏     | 508/1200 [58:20<2:32:18, 13.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 507: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  42%|████▏     | 509/1200 [58:33<2:31:25, 13.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 508: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  42%|████▎     | 510/1200 [58:48<2:37:27, 13.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 509: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  43%|████▎     | 511/1200 [58:59<2:28:46, 12.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 510: 原始预测: ['Yes. The value \"', 'Yes\\nAnswer: Yes', 'Yes. The value \"', 'Yes. The number \"', 'Yes. The passage states', 'Yes. The passage states', 'Yes. Answer: Yes', 'Yes. The percentage of']\n",
      "GPU memory after batch 510: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  43%|████▎     | 512/1200 [59:12<2:28:33, 12.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 511: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  43%|████▎     | 513/1200 [59:24<2:26:48, 12.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 512: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  43%|████▎     | 514/1200 [59:36<2:23:34, 12.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 513: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  43%|████▎     | 515/1200 [59:48<2:18:49, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 514: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  43%|████▎     | 516/1200 [1:00:03<2:28:11, 13.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 515: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  43%|████▎     | 517/1200 [1:00:17<2:33:03, 13.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 516: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  43%|████▎     | 518/1200 [1:00:28<2:23:25, 12.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 517: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  43%|████▎     | 519/1200 [1:00:38<2:16:12, 12.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 518: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  43%|████▎     | 520/1200 [1:00:50<2:15:16, 11.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 519: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  43%|████▎     | 521/1200 [1:01:03<2:18:49, 12.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 520: 原始预测: ['Yes. The number \"', 'Yes. The number \"', 'Yes. The passage mentions', 'Yes. The number \"', 'Yes\\nAnswer: Yes', 'Yes\\nAnswer: Yes', 'Yes. The number \"', 'Yes. Answer: No']\n",
      "GPU memory after batch 520: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  44%|████▎     | 522/1200 [1:01:18<2:27:50, 13.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 521: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  44%|████▎     | 523/1200 [1:01:29<2:21:18, 12.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 522: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  44%|████▎     | 524/1200 [1:01:41<2:16:32, 12.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 523: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  44%|████▍     | 525/1200 [1:01:54<2:19:30, 12.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 524: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  44%|████▍     | 526/1200 [1:02:05<2:15:09, 12.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 525: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  44%|████▍     | 527/1200 [1:02:19<2:23:13, 12.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 526: 12.67 GB\n",
      "批次推理失败（尝试 1/3）：CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 15.89 GiB of which 1.08 GiB is free. Process 7398 has 14.81 GiB memory in use. Of the allocated memory 13.19 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "GPU memory after batch 527: 12.67 GB\n",
      "批次推理失败（尝试 2/3）：CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 15.89 GiB of which 1.08 GiB is free. Process 7398 has 14.81 GiB memory in use. Of the allocated memory 13.19 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "GPU memory after batch 527: 12.67 GB\n",
      "批次推理失败（尝试 3/3）：CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 15.89 GiB of which 1.08 GiB is free. Process 7398 has 14.81 GiB memory in use. Of the allocated memory 13.19 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  44%|████▍     | 528/1200 [1:02:57<3:47:45, 20.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 527 推理失败，跳过\n",
      "GPU memory after batch 527: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  44%|████▍     | 529/1200 [1:03:10<3:21:06, 17.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 528: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  44%|████▍     | 530/1200 [1:03:21<2:58:17, 15.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 529: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  44%|████▍     | 531/1200 [1:03:34<2:46:44, 14.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 530: 原始预测: ['Yes. The passage states', 'Yes. The passage states', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The \"1', 'Yes. The passage mentions', 'Yes. The passage mentions']\n",
      "GPU memory after batch 530: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  44%|████▍     | 532/1200 [1:03:45<2:33:50, 13.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 531: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  44%|████▍     | 533/1200 [1:03:59<2:35:47, 14.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 532: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  44%|████▍     | 534/1200 [1:04:13<2:34:04, 13.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 533: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  45%|████▍     | 535/1200 [1:04:25<2:26:49, 13.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 534: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  45%|████▍     | 536/1200 [1:04:38<2:27:49, 13.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 535: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  45%|████▍     | 537/1200 [1:04:51<2:26:11, 13.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 536: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  45%|████▍     | 538/1200 [1:05:03<2:22:38, 12.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 537: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  45%|████▍     | 539/1200 [1:05:16<2:20:20, 12.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 538: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  45%|████▌     | 540/1200 [1:05:29<2:23:16, 13.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 539: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  45%|████▌     | 541/1200 [1:05:43<2:24:08, 13.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 540: 原始预测: ['No\\nQuestion: Is', 'Yes\\nQuestion: Is', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The passage states', 'Yes. The passage mentions', 'Yes. The passage mentions', 'Yes. The passage mentions']\n",
      "GPU memory after batch 540: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  45%|████▌     | 542/1200 [1:05:56<2:22:58, 13.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 541: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  45%|████▌     | 543/1200 [1:06:10<2:26:32, 13.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 542: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  45%|████▌     | 544/1200 [1:06:24<2:29:52, 13.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 543: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  45%|████▌     | 545/1200 [1:06:36<2:25:03, 13.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 544: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  46%|████▌     | 546/1200 [1:06:51<2:29:29, 13.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 545: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  46%|████▌     | 547/1200 [1:07:06<2:31:43, 13.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 546: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  46%|████▌     | 548/1200 [1:07:19<2:28:16, 13.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 547: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  46%|████▌     | 549/1200 [1:07:30<2:19:12, 12.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 548: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  46%|████▌     | 550/1200 [1:07:43<2:19:26, 12.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 549: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  46%|████▌     | 551/1200 [1:07:56<2:21:18, 13.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 550: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The passage mentions', 'Yes. The passage mentions', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 550: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  46%|████▌     | 552/1200 [1:08:11<2:27:16, 13.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 551: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  46%|████▌     | 553/1200 [1:08:25<2:26:34, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 552: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  46%|████▌     | 554/1200 [1:08:39<2:30:52, 14.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 553: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  46%|████▋     | 555/1200 [1:08:54<2:33:42, 14.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 554: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  46%|████▋     | 556/1200 [1:09:06<2:24:59, 13.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 555: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  46%|████▋     | 557/1200 [1:09:21<2:29:30, 13.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 556: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  46%|████▋     | 558/1200 [1:09:36<2:32:39, 14.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 557: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  47%|████▋     | 559/1200 [1:09:46<2:19:05, 13.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 558: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  47%|████▋     | 560/1200 [1:09:59<2:17:17, 12.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 559: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  47%|████▋     | 561/1200 [1:10:14<2:23:47, 13.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 560: 原始预测: ['of plays later, the', '28-yard completion', 'of the second half,', 'of the second half,', 'by tight end Aaron Hernandez', 'by tight end Aaron Hernandez', 'defensive end Elvis Dumerv', 'defensive end Elvis Dumerv']\n",
      "GPU memory after batch 560: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  47%|████▋     | 562/1200 [1:10:29<2:28:11, 13.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 561: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  47%|████▋     | 563/1200 [1:10:44<2:31:12, 14.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 562: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  47%|████▋     | 564/1200 [1:10:59<2:33:13, 14.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 563: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  47%|████▋     | 565/1200 [1:11:11<2:26:34, 13.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 564: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  47%|████▋     | 566/1200 [1:11:23<2:21:22, 13.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 565: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  47%|████▋     | 567/1200 [1:11:34<2:13:21, 12.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 566: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  47%|████▋     | 568/1200 [1:11:49<2:20:33, 13.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 567: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  47%|████▋     | 569/1200 [1:12:03<2:23:06, 13.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 568: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  48%|████▊     | 570/1200 [1:12:15<2:15:29, 12.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 569: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  48%|████▊     | 571/1200 [1:12:26<2:11:22, 12.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 570: 原始预测: ['Yes. Answer: Yes', 'Yes\\nAnswer: Yes', 'Yes. The passage states', 'Yes. Answer: Yes', 'Yes. The passage mentions', 'Yes. Answer: Yes', 'Yes. The passage mentions', 'Yes. The passage mentions']\n",
      "GPU memory after batch 570: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  48%|████▊     | 572/1200 [1:12:40<2:14:28, 12.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 571: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  48%|████▊     | 573/1200 [1:12:51<2:10:08, 12.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 572: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  48%|████▊     | 574/1200 [1:13:06<2:17:49, 13.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 573: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  48%|████▊     | 575/1200 [1:13:19<2:14:03, 12.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 574: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  48%|████▊     | 576/1200 [1:13:34<2:20:30, 13.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 575: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  48%|████▊     | 577/1200 [1:13:48<2:24:49, 13.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 576: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  48%|████▊     | 578/1200 [1:14:02<2:23:40, 13.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 577: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  48%|████▊     | 579/1200 [1:14:17<2:26:52, 14.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 578: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  48%|████▊     | 580/1200 [1:14:32<2:28:56, 14.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 579: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  48%|████▊     | 581/1200 [1:14:47<2:30:25, 14.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 580: 原始预测: ['left in the half,', 'minutes left in the half', 'points. The Patriots,', 'a 4th-and', 'points. The Patriots,', '. The Patriots, on', 'Yes. The number \"', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 580: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  48%|████▊     | 582/1200 [1:15:02<2:31:25, 14.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 581: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  49%|████▊     | 583/1200 [1:15:17<2:30:36, 14.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 582: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  49%|████▊     | 584/1200 [1:15:31<2:31:19, 14.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 583: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  49%|████▉     | 585/1200 [1:15:46<2:31:49, 14.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 584: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  49%|████▉     | 586/1200 [1:15:58<2:22:17, 13.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 585: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  49%|████▉     | 587/1200 [1:16:11<2:19:07, 13.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 586: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  49%|████▉     | 588/1200 [1:16:24<2:15:00, 13.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 587: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  49%|████▉     | 589/1200 [1:16:36<2:13:32, 13.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 588: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  49%|████▉     | 590/1200 [1:16:47<2:05:56, 12.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 589: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  49%|████▉     | 591/1200 [1:16:57<1:59:44, 11.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 590: 原始预测: ['Yes. The passage states', 'Yes. The passage mentions', 'Yes. The passage states', 'Yes\\nAnswer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 590: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  49%|████▉     | 592/1200 [1:17:12<2:09:12, 12.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 591: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  49%|████▉     | 593/1200 [1:17:25<2:09:31, 12.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 592: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  50%|████▉     | 594/1200 [1:17:38<2:07:57, 12.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 593: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  50%|████▉     | 595/1200 [1:17:51<2:08:09, 12.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 594: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  50%|████▉     | 596/1200 [1:18:03<2:06:02, 12.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 595: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  50%|████▉     | 597/1200 [1:18:18<2:13:16, 13.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 596: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  50%|████▉     | 598/1200 [1:18:33<2:18:10, 13.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 597: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  50%|████▉     | 599/1200 [1:18:48<2:21:38, 14.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 598: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  50%|█████     | 600/1200 [1:19:03<2:23:55, 14.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 599: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  50%|█████     | 601/1200 [1:19:17<2:25:22, 14.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 600: 原始预测: ['drive of the third quarter', 'the next drive, the', 'a punt, the Patriots', 'a punt, the Patriots', '007 season.', 'of the game, and', 'in the league. The', 'in the league. The']\n",
      "GPU memory after batch 600: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  50%|█████     | 602/1200 [1:19:32<2:26:17, 14.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 601: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  50%|█████     | 603/1200 [1:19:47<2:26:57, 14.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 602: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  50%|█████     | 604/1200 [1:20:02<2:27:19, 14.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 603: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  50%|█████     | 605/1200 [1:20:17<2:27:32, 14.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 604: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  50%|█████     | 606/1200 [1:20:32<2:27:34, 14.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 605: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  51%|█████     | 607/1200 [1:20:47<2:27:33, 14.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 606: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  51%|█████     | 608/1200 [1:21:00<2:21:19, 14.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 607: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  51%|█████     | 609/1200 [1:21:15<2:23:02, 14.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 608: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  51%|█████     | 610/1200 [1:21:27<2:15:13, 13.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 609: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  51%|█████     | 611/1200 [1:21:40<2:12:02, 13.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 610: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The passage mentions', 'Yes. Answer: Yes', 'Yes. The passage mentions', 'Yes. The passage states', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 610: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  51%|█████     | 612/1200 [1:21:55<2:15:18, 13.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 611: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  51%|█████     | 613/1200 [1:22:10<2:18:30, 14.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 612: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  51%|█████     | 614/1200 [1:22:21<2:09:43, 13.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 613: 12.67 GB\n",
      "批次推理失败（尝试 1/3）：CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 15.89 GiB of which 1.05 GiB is free. Process 7398 has 14.84 GiB memory in use. Of the allocated memory 13.20 GiB is allocated by PyTorch, and 1.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "GPU memory after batch 614: 12.67 GB\n",
      "批次推理失败（尝试 2/3）：CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 15.89 GiB of which 1.05 GiB is free. Process 7398 has 14.84 GiB memory in use. Of the allocated memory 13.20 GiB is allocated by PyTorch, and 1.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "GPU memory after batch 614: 12.67 GB\n",
      "批次推理失败（尝试 3/3）：CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 15.89 GiB of which 1.05 GiB is free. Process 7398 has 14.84 GiB memory in use. Of the allocated memory 13.20 GiB is allocated by PyTorch, and 1.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  51%|█████▏    | 615/1200 [1:23:06<3:43:35, 22.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 614 推理失败，跳过\n",
      "GPU memory after batch 614: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  51%|█████▏    | 616/1200 [1:23:19<3:12:44, 19.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 615: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  51%|█████▏    | 617/1200 [1:23:31<2:50:14, 17.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 616: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  52%|█████▏    | 618/1200 [1:23:43<2:34:27, 15.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 617: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  52%|█████▏    | 619/1200 [1:23:58<2:31:27, 15.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 618: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  52%|█████▏    | 620/1200 [1:24:13<2:27:46, 15.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 619: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  52%|█████▏    | 621/1200 [1:24:28<2:26:36, 15.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 620: 原始预测: ['Yes. The passage states', 'Yes. The final score', 'Yes. The passage mentions', 'Yes. The value \"', \", and the Chargers'\", \", and the Chargers'\", 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 620: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  52%|█████▏    | 622/1200 [1:24:39<2:16:37, 14.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 621: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  52%|█████▏    | 623/1200 [1:24:54<2:18:41, 14.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 622: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  52%|█████▏    | 624/1200 [1:25:09<2:17:49, 14.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 623: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  52%|█████▏    | 625/1200 [1:25:24<2:19:22, 14.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 624: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  52%|█████▏    | 626/1200 [1:25:39<2:20:24, 14.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 625: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  52%|█████▏    | 627/1200 [1:25:53<2:20:57, 14.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 626: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  52%|█████▏    | 628/1200 [1:26:08<2:21:22, 14.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 627: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  52%|█████▏    | 629/1200 [1:26:21<2:14:48, 14.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 628: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  52%|█████▎    | 630/1200 [1:26:36<2:16:53, 14.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 629: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  53%|█████▎    | 631/1200 [1:26:51<2:18:15, 14.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 630: 原始预测: [\"Broncos' 28\", 'giving the Broncos the', 'Yes. Answer: No', 'Yes. Answer: Yes', 'Yes. Answer: No', 'Yes. Answer: No', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 630: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  53%|█████▎    | 632/1200 [1:27:06<2:19:09, 14.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 631: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  53%|█████▎    | 633/1200 [1:27:21<2:19:41, 14.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 632: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  53%|█████▎    | 634/1200 [1:27:36<2:20:02, 14.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 633: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  53%|█████▎    | 635/1200 [1:27:51<2:20:06, 14.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 634: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  53%|█████▎    | 636/1200 [1:28:06<2:20:06, 14.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 635: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  53%|█████▎    | 637/1200 [1:28:21<2:20:07, 14.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 636: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  53%|█████▎    | 638/1200 [1:28:36<2:20:03, 14.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 637: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  53%|█████▎    | 639/1200 [1:28:51<2:19:53, 14.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 638: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  53%|█████▎    | 640/1200 [1:29:06<2:19:40, 14.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 639: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  53%|█████▎    | 641/1200 [1:29:21<2:19:26, 14.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 640: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', '8-play, 5', '-yard TD pass to Brandon']\n",
      "GPU memory after batch 640: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  54%|█████▎    | 642/1200 [1:29:36<2:19:15, 14.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 641: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  54%|█████▎    | 643/1200 [1:29:51<2:19:01, 14.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 642: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  54%|█████▎    | 644/1200 [1:30:06<2:18:45, 14.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 643: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  54%|█████▍    | 645/1200 [1:30:21<2:18:30, 14.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 644: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  54%|█████▍    | 646/1200 [1:30:36<2:18:17, 14.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 645: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  54%|█████▍    | 647/1200 [1:30:50<2:16:43, 14.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 646: 12.67 GB\n",
      "批次推理失败（尝试 1/3）：CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 15.89 GiB of which 1.05 GiB is free. Process 7398 has 14.84 GiB memory in use. Of the allocated memory 13.20 GiB is allocated by PyTorch, and 1.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "GPU memory after batch 647: 12.67 GB\n",
      "批次推理失败（尝试 2/3）：CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 15.89 GiB of which 1.05 GiB is free. Process 7398 has 14.84 GiB memory in use. Of the allocated memory 13.20 GiB is allocated by PyTorch, and 1.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "GPU memory after batch 647: 12.67 GB\n",
      "批次推理失败（尝试 3/3）：CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 15.89 GiB of which 1.05 GiB is free. Process 7398 has 14.84 GiB memory in use. Of the allocated memory 13.20 GiB is allocated by PyTorch, and 1.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  54%|█████▍    | 648/1200 [1:31:36<3:40:58, 24.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 647 推理失败，跳过\n",
      "GPU memory after batch 647: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  54%|█████▍    | 649/1200 [1:31:51<3:15:39, 21.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 648: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  54%|█████▍    | 650/1200 [1:32:06<2:57:55, 19.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 649: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  54%|█████▍    | 651/1200 [1:32:21<2:45:27, 18.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 650: 原始预测: ['Yes. The passage states', 'Yes. Answer: Yes', 'Shockey in the head', 'Shockey in the head', \"a Rams' punt,\", 'held the Rams to a', ', with Manning finding Pl', ', with Manning finding Pl']\n",
      "GPU memory after batch 650: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  54%|█████▍    | 652/1200 [1:32:36<2:36:41, 17.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 651: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  54%|█████▍    | 653/1200 [1:32:51<2:30:27, 16.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 652: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  55%|█████▍    | 654/1200 [1:33:06<2:26:03, 16.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 653: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  55%|█████▍    | 655/1200 [1:33:21<2:22:54, 15.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 654: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  55%|█████▍    | 656/1200 [1:33:36<2:20:37, 15.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 655: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  55%|█████▍    | 657/1200 [1:33:51<2:18:56, 15.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 656: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  55%|█████▍    | 658/1200 [1:34:06<2:17:40, 15.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 657: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  55%|█████▍    | 659/1200 [1:34:21<2:16:43, 15.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 658: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  55%|█████▌    | 660/1200 [1:34:36<2:15:58, 15.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 659: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  55%|█████▌    | 661/1200 [1:34:50<2:15:19, 15.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 660: 原始预测: ['004. The', '004. The', 'and 10-yard', '-, 6-,', '10-yard lines', '5-yard lines.', 'on his left shoulder.', 'on his left shoulder.']\n",
      "GPU memory after batch 660: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  55%|█████▌    | 662/1200 [1:35:05<2:14:54, 15.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 661: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  55%|█████▌    | 663/1200 [1:35:20<2:14:28, 15.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 662: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  55%|█████▌    | 664/1200 [1:35:35<2:14:07, 15.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 663: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  55%|█████▌    | 665/1200 [1:35:50<2:13:44, 15.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 664: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  56%|█████▌    | 666/1200 [1:36:05<2:13:28, 15.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 665: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  56%|█████▌    | 667/1200 [1:36:20<2:13:10, 14.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 666: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  56%|█████▌    | 668/1200 [1:36:35<2:12:51, 14.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 667: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  56%|█████▌    | 669/1200 [1:36:50<2:12:36, 14.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 668: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  56%|█████▌    | 670/1200 [1:37:05<2:12:19, 14.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 669: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  56%|█████▌    | 671/1200 [1:37:19<2:08:26, 14.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 670: 原始预测: ['Yes\\nAnswer: No', 'Yes. The number \"', 'Yes\\nAnswer: Yes', 'Yes\\nAnswer: Yes', 'Yes\\nAnswer: Yes', 'Yes\\nAnswer: Yes', 'Yes. The time remaining', 'Yes\\nAnswer: Yes']\n",
      "GPU memory after batch 670: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  56%|█████▌    | 672/1200 [1:37:28<1:53:11, 12.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 671: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  56%|█████▌    | 673/1200 [1:37:40<1:50:35, 12.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 672: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  56%|█████▌    | 674/1200 [1:37:55<1:56:36, 13.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 673: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  56%|█████▋    | 675/1200 [1:38:10<2:00:43, 13.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 674: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  56%|█████▋    | 676/1200 [1:38:25<2:03:33, 14.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 675: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  56%|█████▋    | 677/1200 [1:38:40<2:05:32, 14.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 676: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  56%|█████▋    | 678/1200 [1:38:54<2:04:37, 14.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 677: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  57%|█████▋    | 679/1200 [1:39:07<2:00:52, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 678: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  57%|█████▋    | 680/1200 [1:39:22<2:03:25, 14.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 679: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  57%|█████▋    | 681/1200 [1:39:37<2:05:04, 14.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 680: 原始预测: ['were in the red zone', \"' 10-yard\", 'were attempting to convert a', 'Patriots were attempting a', 'the Patriots were in the', 'were in the red zone', '38-yard field', 'half with a 3']\n",
      "GPU memory after batch 680: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  57%|█████▋    | 682/1200 [1:39:52<2:06:13, 14.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 681: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  57%|█████▋    | 683/1200 [1:40:06<2:05:49, 14.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 682: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  57%|█████▋    | 684/1200 [1:40:21<2:06:34, 14.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 683: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  57%|█████▋    | 685/1200 [1:40:36<2:07:00, 14.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 684: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  57%|█████▋    | 686/1200 [1:40:51<2:07:18, 14.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 685: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  57%|█████▋    | 687/1200 [1:41:04<2:02:10, 14.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 686: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  57%|█████▋    | 688/1200 [1:41:18<2:01:32, 14.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 687: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  57%|█████▋    | 689/1200 [1:41:33<2:01:54, 14.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 688: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  57%|█████▊    | 690/1200 [1:41:46<1:57:56, 13.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 689: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  58%|█████▊    | 691/1200 [1:41:59<1:57:03, 13.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 690: 原始预测: ['Yes. The passage states', 'Yes. The final score', 'Yes. The passage mentions', 'Yes. The passage states', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 690: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  58%|█████▊    | 692/1200 [1:42:14<1:59:51, 14.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 691: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  58%|█████▊    | 693/1200 [1:42:28<1:58:01, 13.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 692: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  58%|█████▊    | 694/1200 [1:42:43<2:00:26, 14.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 693: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  58%|█████▊    | 695/1200 [1:42:57<2:01:02, 14.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 694: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  58%|█████▊    | 696/1200 [1:43:12<2:01:25, 14.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 695: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  58%|█████▊    | 697/1200 [1:43:23<1:53:11, 13.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 696: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  58%|█████▊    | 698/1200 [1:43:38<1:56:46, 13.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 697: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  58%|█████▊    | 699/1200 [1:43:53<1:58:44, 14.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 698: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  58%|█████▊    | 700/1200 [1:44:08<2:00:30, 14.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 699: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  58%|█████▊    | 701/1200 [1:44:22<1:57:33, 14.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 700: 原始预测: ['Yes. The passage mentions', 'Yes\\nAnswer: Yes', 'Yes. The number \"', 'Yes. The mention of', 'Yes. The \"5', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 700: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  58%|█████▊    | 702/1200 [1:44:37<1:59:29, 14.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 701: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  59%|█████▊    | 703/1200 [1:44:52<2:00:48, 14.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 702: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  59%|█████▊    | 704/1200 [1:45:03<1:51:54, 13.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 703: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  59%|█████▉    | 705/1200 [1:45:16<1:50:20, 13.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 704: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  59%|█████▉    | 706/1200 [1:45:31<1:54:11, 13.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 705: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  59%|█████▉    | 707/1200 [1:45:46<1:56:47, 14.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 706: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  59%|█████▉    | 708/1200 [1:46:01<1:58:30, 14.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 707: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  59%|█████▉    | 709/1200 [1:46:16<1:59:43, 14.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 708: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  59%|█████▉    | 710/1200 [1:46:31<2:00:24, 14.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 709: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  59%|█████▉    | 711/1200 [1:46:46<2:00:50, 14.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 710: 原始预测: ['Yes\\nAnswer: Yes', 'Yes\\nAnswer: Yes', '.  The Cowboys would', 'the Cowboys.  The', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes\\nAnswer: Yes', 'Yes\\nAnswer: Yes']\n",
      "GPU memory after batch 710: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  59%|█████▉    | 712/1200 [1:46:58<1:54:18, 14.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 711: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  59%|█████▉    | 713/1200 [1:47:13<1:56:22, 14.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 712: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  60%|█████▉    | 714/1200 [1:47:25<1:49:38, 13.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 713: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  60%|█████▉    | 715/1200 [1:47:38<1:47:48, 13.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 714: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  60%|█████▉    | 716/1200 [1:47:49<1:43:45, 12.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 715: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  60%|█████▉    | 717/1200 [1:48:04<1:48:44, 13.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 716: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  60%|█████▉    | 718/1200 [1:48:19<1:52:04, 13.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 717: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  60%|█████▉    | 719/1200 [1:48:34<1:54:21, 14.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 718: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  60%|██████    | 720/1200 [1:48:49<1:55:53, 14.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 719: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  60%|██████    | 721/1200 [1:49:04<1:56:56, 14.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 720: 原始预测: ['1992.', '1998', 'was tackled at the Patriots', 'was tackled at the Patriots', '-10) Q', '27-10', 'Yes\\nAnswer: Yes', 'Yes\\nAnswer: Yes']\n",
      "GPU memory after batch 720: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  60%|██████    | 722/1200 [1:49:19<1:57:35, 14.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 721: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  60%|██████    | 723/1200 [1:49:34<1:57:56, 14.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 722: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  60%|██████    | 724/1200 [1:49:49<1:58:08, 14.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 723: 12.67 GB\n",
      "批次推理失败（尝试 1/3）：CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 15.89 GiB of which 1.16 GiB is free. Process 7398 has 14.73 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 1.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "GPU memory after batch 724: 12.67 GB\n",
      "批次推理失败（尝试 2/3）：CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 15.89 GiB of which 1.16 GiB is free. Process 7398 has 14.73 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 1.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "GPU memory after batch 724: 12.67 GB\n",
      "批次推理失败（尝试 3/3）：CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 15.89 GiB of which 1.16 GiB is free. Process 7398 has 14.73 GiB memory in use. Of the allocated memory 13.15 GiB is allocated by PyTorch, and 1.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  60%|██████    | 725/1200 [1:50:29<2:55:48, 22.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 724 推理失败，跳过\n",
      "GPU memory after batch 724: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  60%|██████    | 726/1200 [1:50:44<2:38:23, 20.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 725: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  61%|██████    | 727/1200 [1:50:59<2:26:07, 18.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 726: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  61%|██████    | 728/1200 [1:51:14<2:17:29, 17.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 727: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  61%|██████    | 729/1200 [1:51:29<2:11:23, 16.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 728: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  61%|██████    | 730/1200 [1:51:44<2:07:04, 16.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 729: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  61%|██████    | 731/1200 [1:51:59<2:03:58, 15.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 730: 原始预测: ['2004', '2004', 'Yes. The passage mentions', 'Yes. The passage mentions', '10-1.', 'are 10-', 'Yes. The number \"', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 730: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  61%|██████    | 732/1200 [1:52:12<1:58:29, 15.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 731: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  61%|██████    | 733/1200 [1:52:26<1:53:59, 14.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 732: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  61%|██████    | 734/1200 [1:52:41<1:54:37, 14.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 733: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  61%|██████▏   | 735/1200 [1:52:56<1:55:01, 14.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 734: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  61%|██████▏   | 736/1200 [1:53:07<1:45:14, 13.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 735: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  61%|██████▏   | 737/1200 [1:53:17<1:37:02, 12.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 736: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  62%|██████▏   | 738/1200 [1:53:27<1:32:25, 12.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 737: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  62%|██████▏   | 739/1200 [1:53:38<1:28:59, 11.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 738: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  62%|██████▏   | 740/1200 [1:53:49<1:26:35, 11.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 739: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  62%|██████▏   | 741/1200 [1:54:01<1:29:18, 11.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 740: 原始预测: ['Yes. Answer: No', 'Yes\\nAnswer: Yes', 'Yes. The passage states', 'Yes. The number \"', 'Yes. The number \"', 'Yes. The passage states', 'Yes. Answer: No', 'Yes. Answer: No']\n",
      "GPU memory after batch 740: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  62%|██████▏   | 742/1200 [1:54:12<1:27:26, 11.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 741: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  62%|██████▏   | 743/1200 [1:54:25<1:30:30, 11.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 742: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  62%|██████▏   | 744/1200 [1:54:37<1:29:52, 11.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 743: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  62%|██████▏   | 745/1200 [1:54:51<1:34:59, 12.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 744: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  62%|██████▏   | 746/1200 [1:55:02<1:32:39, 12.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 745: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  62%|██████▏   | 747/1200 [1:55:13<1:29:34, 11.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 746: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  62%|██████▏   | 748/1200 [1:55:24<1:26:46, 11.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 747: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  62%|██████▏   | 749/1200 [1:55:34<1:23:37, 11.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 748: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  62%|██████▎   | 750/1200 [1:55:45<1:21:58, 10.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 749: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  63%|██████▎   | 751/1200 [1:55:55<1:20:43, 10.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 750: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The mention of', 'Yes. Answer: Yes', 'Yes. The number \"', 'Yes. The number \"']\n",
      "GPU memory after batch 750: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  63%|██████▎   | 752/1200 [1:56:07<1:21:45, 10.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 751: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  63%|██████▎   | 753/1200 [1:56:17<1:19:48, 10.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 752: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  63%|██████▎   | 754/1200 [1:56:27<1:18:19, 10.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 753: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  63%|██████▎   | 755/1200 [1:56:37<1:17:11, 10.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 754: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  63%|██████▎   | 756/1200 [1:56:48<1:18:46, 10.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 755: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  63%|██████▎   | 757/1200 [1:57:01<1:22:57, 11.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 756: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  63%|██████▎   | 758/1200 [1:57:13<1:25:14, 11.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 757: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  63%|██████▎   | 759/1200 [1:57:25<1:26:15, 11.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 758: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  63%|██████▎   | 760/1200 [1:57:35<1:22:06, 11.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 759: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  63%|██████▎   | 761/1200 [1:57:46<1:20:55, 11.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 760: 原始预测: ['Yes. The number \"', 'Yes. The number \"', 'Yes. The passage states', 'Yes. The number \"', 'Yes\\nAnswer: Yes', 'Yes\\nAnswer: Yes', 'Yes\\nAnswer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 760: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  64%|██████▎   | 762/1200 [1:57:57<1:20:51, 11.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 761: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  64%|██████▎   | 763/1200 [1:58:10<1:23:33, 11.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 762: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  64%|██████▎   | 764/1200 [1:58:20<1:21:09, 11.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 763: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  64%|██████▍   | 765/1200 [1:58:32<1:23:22, 11.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 764: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  64%|██████▍   | 766/1200 [1:58:42<1:19:31, 10.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 765: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  64%|██████▍   | 767/1200 [1:58:55<1:23:38, 11.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 766: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  64%|██████▍   | 768/1200 [1:59:06<1:21:22, 11.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 767: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  64%|██████▍   | 769/1200 [1:59:20<1:28:39, 12.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 768: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  64%|██████▍   | 770/1200 [1:59:32<1:25:45, 11.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 769: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  64%|██████▍   | 771/1200 [1:59:45<1:28:01, 12.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 770: 原始预测: ['Yes. The passage mentions', 'Yes. The passage mentions', 'Yes. The number \"', 'Yes. The number \"', 'Yes. The mention of', 'Yes. The date \"', 'Yes. The mention of', 'Yes. The mention of']\n",
      "GPU memory after batch 770: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  64%|██████▍   | 772/1200 [1:59:55<1:23:12, 11.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 771: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  64%|██████▍   | 773/1200 [2:00:05<1:20:49, 11.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 772: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  64%|██████▍   | 774/1200 [2:00:15<1:17:29, 10.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 773: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  65%|██████▍   | 775/1200 [2:00:28<1:20:48, 11.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 774: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  65%|██████▍   | 776/1200 [2:00:42<1:26:04, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 775: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  65%|██████▍   | 777/1200 [2:00:53<1:24:30, 11.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 776: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  65%|██████▍   | 778/1200 [2:01:05<1:23:49, 11.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 777: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  65%|██████▍   | 779/1200 [2:01:15<1:18:16, 11.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 778: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  65%|██████▌   | 780/1200 [2:01:25<1:16:07, 10.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 779: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  65%|██████▌   | 781/1200 [2:01:38<1:20:25, 11.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 780: 原始预测: ['No\\nQuestion: Is', 'No\\nQuestion: Is', 'Yes. The passage mentions', 'Yes. The mention of', 'Yes\\nAnswer: Yes', 'Yes. Answer: Yes', 'Yes. The oxidation state', 'Yes. The oxidation state']\n",
      "GPU memory after batch 780: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  65%|██████▌   | 782/1200 [2:01:50<1:22:24, 11.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 781: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  65%|██████▌   | 783/1200 [2:02:00<1:17:34, 11.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 782: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  65%|██████▌   | 784/1200 [2:02:10<1:15:15, 10.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 783: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  65%|██████▌   | 785/1200 [2:02:20<1:13:45, 10.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 784: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  66%|██████▌   | 786/1200 [2:02:30<1:12:39, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 785: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  66%|██████▌   | 787/1200 [2:02:41<1:12:41, 10.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 786: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  66%|██████▌   | 788/1200 [2:02:50<1:08:52, 10.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 787: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  66%|██████▌   | 789/1200 [2:03:01<1:11:49, 10.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 788: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  66%|██████▌   | 790/1200 [2:03:13<1:13:48, 10.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 789: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  66%|██████▌   | 791/1200 [2:03:26<1:19:06, 11.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 790: 原始预测: ['Yes. The number \"', 'Yes. The number \"', 'Yes. The number \"', 'Yes. The number \"', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The number \"', 'Yes. The number \"']\n",
      "GPU memory after batch 790: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  66%|██████▌   | 792/1200 [2:03:40<1:22:59, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 791: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  66%|██████▌   | 793/1200 [2:03:54<1:26:25, 12.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 792: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  66%|██████▌   | 794/1200 [2:04:07<1:26:45, 12.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 793: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  66%|██████▋   | 795/1200 [2:04:17<1:19:47, 11.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 794: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  66%|██████▋   | 796/1200 [2:04:27<1:16:21, 11.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 795: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  66%|██████▋   | 797/1200 [2:04:37<1:13:39, 10.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 796: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  66%|██████▋   | 798/1200 [2:04:48<1:14:05, 11.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 797: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  67%|██████▋   | 799/1200 [2:05:02<1:18:33, 11.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 798: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  67%|██████▋   | 800/1200 [2:05:15<1:21:54, 12.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 799: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  67%|██████▋   | 801/1200 [2:05:27<1:20:33, 12.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 800: 原始预测: ['Yes. Answer: Yes', 'Yes. The number \"', 'Yes. The passage states', 'Yes. The passage states', 'Yes. The passage contains', 'Yes. The number \"', 'Yes. The date \"', 'Yes. The date \"']\n",
      "GPU memory after batch 800: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  67%|██████▋   | 802/1200 [2:05:36<1:14:17, 11.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 801: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  67%|██████▋   | 803/1200 [2:05:47<1:13:55, 11.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 802: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  67%|██████▋   | 804/1200 [2:05:58<1:13:39, 11.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 803: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  67%|██████▋   | 805/1200 [2:06:09<1:13:42, 11.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 804: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  67%|██████▋   | 806/1200 [2:06:21<1:13:40, 11.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 805: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  67%|██████▋   | 807/1200 [2:06:31<1:11:23, 10.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 806: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  67%|██████▋   | 808/1200 [2:06:41<1:09:35, 10.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 807: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  67%|██████▋   | 809/1200 [2:06:50<1:07:21, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 808: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  68%|██████▊   | 810/1200 [2:07:00<1:05:34, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 809: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  68%|██████▊   | 811/1200 [2:07:11<1:07:03, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 810: 原始预测: ['Yes. The passage mentions', 'Yes. The passage states', 'Yes. The passage mentions', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The mention of', 'Yes. The mention of']\n",
      "GPU memory after batch 810: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  68%|██████▊   | 812/1200 [2:07:21<1:05:55, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 811: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  68%|██████▊   | 813/1200 [2:07:31<1:06:46, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 812: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  68%|██████▊   | 814/1200 [2:07:40<1:03:27,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 813: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  68%|██████▊   | 815/1200 [2:07:52<1:06:05, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 814: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  68%|██████▊   | 816/1200 [2:08:02<1:07:11, 10.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 815: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  68%|██████▊   | 817/1200 [2:08:14<1:08:11, 10.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 816: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  68%|██████▊   | 818/1200 [2:08:24<1:07:56, 10.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 817: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  68%|██████▊   | 819/1200 [2:08:37<1:11:33, 11.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 818: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  68%|██████▊   | 820/1200 [2:08:48<1:11:55, 11.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 819: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  68%|██████▊   | 821/1200 [2:09:00<1:12:07, 11.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 820: 原始预测: ['Yes. The number \"', 'Yes. The number \"', 'Yes. The passage mentions', 'Yes. The number \"', 'Yes. The passage mentions', 'Yes. The \"0', 'Yes. The number \"', 'Yes. The number \"']\n",
      "GPU memory after batch 820: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  68%|██████▊   | 822/1200 [2:09:11<1:11:38, 11.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 821: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  69%|██████▊   | 823/1200 [2:09:22<1:10:10, 11.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 822: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  69%|██████▊   | 824/1200 [2:09:36<1:14:36, 11.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 823: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  69%|██████▉   | 825/1200 [2:09:46<1:11:03, 11.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 824: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  69%|██████▉   | 826/1200 [2:09:56<1:09:31, 11.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 825: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  69%|██████▉   | 827/1200 [2:10:06<1:06:58, 10.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 826: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  69%|██████▉   | 828/1200 [2:10:18<1:07:51, 10.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 827: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  69%|██████▉   | 829/1200 [2:10:28<1:07:05, 10.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 828: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  69%|██████▉   | 830/1200 [2:10:38<1:04:23, 10.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 829: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  69%|██████▉   | 831/1200 [2:10:51<1:08:41, 11.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 830: 原始预测: ['Yes. The mention of', 'Yes. Answer: No', 'Yes. The passage mentions', 'Yes. The mention of', 'Yes. The mention of', 'Yes. The passage mentions', 'Yes. The passage mentions', 'Yes. The \"2']\n",
      "GPU memory after batch 830: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  69%|██████▉   | 832/1200 [2:11:02<1:08:44, 11.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 831: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  69%|██████▉   | 833/1200 [2:11:13<1:08:44, 11.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 832: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  70%|██████▉   | 834/1200 [2:11:23<1:06:31, 10.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 833: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  70%|██████▉   | 835/1200 [2:11:33<1:04:55, 10.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 834: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  70%|██████▉   | 836/1200 [2:11:43<1:02:21, 10.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 835: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  70%|██████▉   | 837/1200 [2:11:56<1:08:10, 11.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 836: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  70%|██████▉   | 838/1200 [2:12:10<1:12:09, 11.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 837: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  70%|██████▉   | 839/1200 [2:12:23<1:14:30, 12.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 838: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  70%|███████   | 840/1200 [2:12:35<1:13:12, 12.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 839: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  70%|███████   | 841/1200 [2:12:50<1:18:04, 13.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 840: 原始预测: ['. The tax burden in', '. The tax burden in', 'Yes. The number \"', 'Yes. The passage states', 'Yes. The error is', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 840: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  70%|███████   | 842/1200 [2:13:00<1:11:42, 12.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 841: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  70%|███████   | 843/1200 [2:13:10<1:08:02, 11.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 842: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  70%|███████   | 844/1200 [2:13:20<1:05:04, 10.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 843: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  70%|███████   | 845/1200 [2:13:30<1:04:24, 10.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 844: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  70%|███████   | 846/1200 [2:13:43<1:08:00, 11.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 845: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  71%|███████   | 847/1200 [2:13:55<1:07:15, 11.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 846: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  71%|███████   | 848/1200 [2:14:05<1:04:44, 11.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 847: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  71%|███████   | 849/1200 [2:14:17<1:07:06, 11.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 848: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  71%|███████   | 850/1200 [2:14:27<1:03:13, 10.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 849: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  71%|███████   | 851/1200 [2:14:37<1:01:45, 10.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 850: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes\\nAnswer: Yes', 'Yes\\nAnswer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 850: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  71%|███████   | 852/1200 [2:14:47<1:00:41, 10.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 851: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  71%|███████   | 853/1200 [2:14:58<1:01:58, 10.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 852: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  71%|███████   | 854/1200 [2:15:10<1:04:32, 11.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 853: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  71%|███████▏  | 855/1200 [2:15:21<1:02:30, 10.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 854: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  71%|███████▏  | 856/1200 [2:15:32<1:03:49, 11.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 855: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  71%|███████▏  | 857/1200 [2:15:44<1:04:51, 11.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 856: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  72%|███████▏  | 858/1200 [2:15:54<1:01:41, 10.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 857: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  72%|███████▏  | 859/1200 [2:16:04<1:00:45, 10.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 858: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  72%|███████▏  | 860/1200 [2:16:14<59:46, 10.55s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 859: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  72%|███████▏  | 861/1200 [2:16:25<59:00, 10.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 860: 原始预测: ['Yes. The number \"', 'Yes. Answer: Yes', 'Yes. The mention of', 'Yes. The mention of', 'Yes. The passage mentions', 'Yes. The passage mentions', 'Yes. The passage mentions', 'Yes. The passage mentions']\n",
      "GPU memory after batch 860: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  72%|███████▏  | 862/1200 [2:16:36<1:01:12, 10.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 861: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  72%|███████▏  | 863/1200 [2:16:48<1:02:32, 11.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 862: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  72%|███████▏  | 864/1200 [2:16:57<57:56, 10.35s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 863: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  72%|███████▏  | 865/1200 [2:17:09<1:01:34, 11.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 864: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  72%|███████▏  | 866/1200 [2:17:21<1:02:42, 11.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 865: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  72%|███████▏  | 867/1200 [2:17:32<1:02:00, 11.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 866: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  72%|███████▏  | 868/1200 [2:17:46<1:07:11, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 867: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  72%|███████▏  | 869/1200 [2:18:01<1:10:55, 12.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 868: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  72%|███████▎  | 870/1200 [2:18:12<1:08:06, 12.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 869: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  73%|███████▎  | 871/1200 [2:18:21<1:02:26, 11.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 870: 原始预测: ['Yes. The number \"', 'Yes. The date \"-', 'Yes. Answer: No', 'Yes. The passage states', 'Yes. The passage mentions', 'Yes. The passage states', 'Yes. The passage mentions', 'Yes. The number \"']\n",
      "GPU memory after batch 870: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  73%|███████▎  | 872/1200 [2:18:31<1:00:08, 11.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 871: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  73%|███████▎  | 873/1200 [2:18:42<59:18, 10.88s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 872: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  73%|███████▎  | 874/1200 [2:18:53<58:44, 10.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 873: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  73%|███████▎  | 875/1200 [2:19:03<57:36, 10.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 874: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  73%|███████▎  | 876/1200 [2:19:12<55:20, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 875: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  73%|███████▎  | 877/1200 [2:19:22<55:07, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 876: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  73%|███████▎  | 878/1200 [2:19:34<57:36, 10.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 877: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  73%|███████▎  | 879/1200 [2:19:47<1:00:53, 11.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 878: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  73%|███████▎  | 880/1200 [2:20:00<1:03:04, 11.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 879: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  73%|███████▎  | 881/1200 [2:20:12<1:02:39, 11.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 880: 原始预测: ['Yes. The number \"', 'Yes. The number \"', 'Yes. The number \"', 'Yes. Answer: Yes', 'Yes. The passage states', 'Yes. The passage states', 'Yes. Answer: No', 'Yes. Answer: No']\n",
      "GPU memory after batch 880: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  74%|███████▎  | 882/1200 [2:20:26<1:06:58, 12.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 881: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  74%|███████▎  | 883/1200 [2:20:39<1:07:27, 12.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 882: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  74%|███████▎  | 884/1200 [2:20:52<1:07:31, 12.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 883: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  74%|███████▍  | 885/1200 [2:21:07<1:09:35, 13.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 884: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  74%|███████▍  | 886/1200 [2:21:19<1:08:25, 13.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 885: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  74%|███████▍  | 887/1200 [2:21:32<1:07:48, 13.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 886: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  74%|███████▍  | 888/1200 [2:21:45<1:07:49, 13.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 887: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  74%|███████▍  | 889/1200 [2:22:00<1:10:40, 13.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 888: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  74%|███████▍  | 890/1200 [2:22:13<1:09:10, 13.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 889: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  74%|███████▍  | 891/1200 [2:22:27<1:08:59, 13.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 890: 原始预测: ['Yes. The \"1', 'Yes\\nAnswer: Yes', 'Yes. The \"1', 'Yes\\nAnswer: Yes', 'Yes. The \"1', 'Yes\\nAnswer: Yes', 'Yes. The number \"', 'Yes. The date \"']\n",
      "GPU memory after batch 890: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  74%|███████▍  | 892/1200 [2:22:40<1:08:08, 13.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 891: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  74%|███████▍  | 893/1200 [2:22:52<1:06:48, 13.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 892: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  74%|███████▍  | 894/1200 [2:23:05<1:06:18, 13.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 893: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  75%|███████▍  | 895/1200 [2:23:18<1:05:55, 12.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 894: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  75%|███████▍  | 896/1200 [2:23:31<1:05:39, 12.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 895: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  75%|███████▍  | 897/1200 [2:23:44<1:05:29, 12.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 896: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  75%|███████▍  | 898/1200 [2:23:56<1:04:01, 12.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 897: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  75%|███████▍  | 899/1200 [2:24:08<1:03:11, 12.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 898: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  75%|███████▌  | 900/1200 [2:24:21<1:03:02, 12.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 899: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  75%|███████▌  | 901/1200 [2:24:36<1:06:25, 13.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 900: 原始预测: ['runners, the 1', 'runners, the 1', 'Yes. Answer: Yes', 'Yes. Yes. No', 'Yes. The number \"', 'Yes. The number \"', 'Yes. The number \"', 'Yes. The number \"']\n",
      "GPU memory after batch 900: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  75%|███████▌  | 902/1200 [2:24:48<1:04:12, 12.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 901: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  75%|███████▌  | 903/1200 [2:25:02<1:05:50, 13.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 902: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  75%|███████▌  | 904/1200 [2:25:16<1:06:54, 13.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 903: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  75%|███████▌  | 905/1200 [2:25:29<1:05:56, 13.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 904: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  76%|███████▌  | 906/1200 [2:25:42<1:04:05, 13.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 905: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  76%|███████▌  | 907/1200 [2:25:55<1:04:21, 13.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 906: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  76%|███████▌  | 908/1200 [2:26:08<1:03:52, 13.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 907: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  76%|███████▌  | 909/1200 [2:26:21<1:03:25, 13.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 908: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  76%|███████▌  | 910/1200 [2:26:34<1:03:05, 13.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 909: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  76%|███████▌  | 911/1200 [2:26:47<1:02:49, 13.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 910: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The number \"', 'Yes. The number \"', 'Yes. The passage states', 'Yes. The number \"']\n",
      "GPU memory after batch 910: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  76%|███████▌  | 912/1200 [2:26:59<1:01:39, 12.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 911: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  76%|███████▌  | 913/1200 [2:27:14<1:03:18, 13.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 912: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  76%|███████▌  | 914/1200 [2:27:26<1:02:07, 13.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 913: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  76%|███████▋  | 915/1200 [2:27:39<1:02:24, 13.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 914: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  76%|███████▋  | 916/1200 [2:27:54<1:04:28, 13.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 915: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  76%|███████▋  | 917/1200 [2:28:09<1:05:39, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 916: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  76%|███████▋  | 918/1200 [2:28:22<1:04:08, 13.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 917: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  77%|███████▋  | 919/1200 [2:28:34<1:01:32, 13.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 918: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  77%|███████▋  | 920/1200 [2:28:47<1:02:00, 13.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 919: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  77%|███████▋  | 921/1200 [2:29:01<1:02:16, 13.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 920: 原始预测: ['Yes. The phone number', 'Yes. The phone number', 'Yes. The phone number', 'Yes. The phone number', 'Yes\\nAnswer: Yes', 'Yes\\nAnswer: Yes', 'Yes. The number \"', 'Yes\\nAnswer: Yes']\n",
      "GPU memory after batch 920: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  77%|███████▋  | 922/1200 [2:29:15<1:02:12, 13.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 921: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  77%|███████▋  | 923/1200 [2:29:27<1:00:46, 13.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 922: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  77%|███████▋  | 924/1200 [2:29:40<59:41, 12.98s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 923: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  77%|███████▋  | 925/1200 [2:29:54<1:01:47, 13.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 924: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  77%|███████▋  | 926/1200 [2:30:08<1:01:26, 13.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 925: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  77%|███████▋  | 927/1200 [2:30:21<1:01:25, 13.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 926: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  77%|███████▋  | 928/1200 [2:30:36<1:02:28, 13.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 927: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  77%|███████▋  | 929/1200 [2:30:50<1:03:05, 13.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 928: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  78%|███████▊  | 930/1200 [2:31:04<1:02:04, 13.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 929: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  78%|███████▊  | 931/1200 [2:31:17<1:00:55, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 930: 原始预测: ['Yes. The date in', 'Yes. The year \"', 'Yes. The passage mentions', 'Yes. The \"0', 'Yes. The passage mentions', 'Yes. The date \"', 'Yes. The passage mentions', 'Yes. The number \"']\n",
      "GPU memory after batch 930: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  78%|███████▊  | 932/1200 [2:31:30<59:44, 13.37s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 931: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  78%|███████▊  | 933/1200 [2:31:42<58:10, 13.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 932: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  78%|███████▊  | 934/1200 [2:31:54<56:51, 12.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 933: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  78%|███████▊  | 935/1200 [2:32:06<55:55, 12.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 934: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  78%|███████▊  | 936/1200 [2:32:19<56:10, 12.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 935: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  78%|███████▊  | 937/1200 [2:32:34<58:54, 13.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 936: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  78%|███████▊  | 938/1200 [2:32:46<56:45, 13.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 937: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  78%|███████▊  | 939/1200 [2:32:59<56:15, 12.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 938: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  78%|███████▊  | 940/1200 [2:33:12<55:26, 12.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 939: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  78%|███████▊  | 941/1200 [2:33:24<54:59, 12.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 940: 原始预测: ['Yes. The number \"', 'Yes. The passage contains', 'Yes. The passage mentions', 'Yes. Answer: Yes', 'Yes\\nAnswer: Yes', 'Yes\\nAnswer: Yes', 'Yes. The passage mentions', 'Yes. The number \"']\n",
      "GPU memory after batch 940: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  78%|███████▊  | 942/1200 [2:33:37<54:08, 12.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 941: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  79%|███████▊  | 943/1200 [2:33:48<52:19, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 942: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  79%|███████▊  | 944/1200 [2:34:00<52:13, 12.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 943: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  79%|███████▉  | 945/1200 [2:34:13<52:39, 12.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 944: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  79%|███████▉  | 946/1200 [2:34:26<53:51, 12.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 945: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  79%|███████▉  | 947/1200 [2:34:39<53:01, 12.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 946: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  79%|███████▉  | 948/1200 [2:34:51<53:10, 12.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 947: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  79%|███████▉  | 949/1200 [2:35:06<55:55, 13.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 948: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  79%|███████▉  | 950/1200 [2:35:18<53:09, 12.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 949: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  79%|███████▉  | 951/1200 [2:35:30<51:45, 12.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 950: 原始预测: ['Yes. The passage mentions', 'Yes. The passage mentions', 'Yes. The passage mentions', 'Yes. The number \"', 'Yes. The date \"', 'Yes. The date \"', 'Yes. The passage mentions', 'Yes. The passage states']\n",
      "GPU memory after batch 950: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  79%|███████▉  | 952/1200 [2:35:41<50:32, 12.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 951: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  79%|███████▉  | 953/1200 [2:35:53<49:40, 12.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 952: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  80%|███████▉  | 954/1200 [2:36:04<48:15, 11.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 953: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  80%|███████▉  | 955/1200 [2:36:13<44:25, 10.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 954: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  80%|███████▉  | 956/1200 [2:36:22<41:39, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 955: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  80%|███████▉  | 957/1200 [2:36:30<39:41,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 956: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  80%|███████▉  | 958/1200 [2:36:41<39:56,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 957: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  80%|███████▉  | 959/1200 [2:36:49<38:24,  9.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 958: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  80%|████████  | 960/1200 [2:36:58<36:45,  9.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 959: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  80%|████████  | 961/1200 [2:37:08<37:45,  9.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 960: 原始预测: ['No\\nQuestion: Is', 'Yes\\nQuestion: Is', 'Yes. The number \"', 'Yes. The number \"', 'Yes. The passage states', 'Yes. The passage contains', 'Yes. The numbers', 'Yes\\nAnswer: Yes']\n",
      "GPU memory after batch 960: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  80%|████████  | 962/1200 [2:37:17<36:45,  9.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 961: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  80%|████████  | 963/1200 [2:37:25<35:33,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 962: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  80%|████████  | 964/1200 [2:37:34<35:07,  8.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 963: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  80%|████████  | 965/1200 [2:37:42<33:39,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 964: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  80%|████████  | 966/1200 [2:37:49<32:36,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 965: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  81%|████████  | 967/1200 [2:37:58<32:26,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 966: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  81%|████████  | 968/1200 [2:38:04<30:12,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 967: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  81%|████████  | 969/1200 [2:38:11<28:28,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 968: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  81%|████████  | 970/1200 [2:38:17<26:55,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 969: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  81%|████████  | 971/1200 [2:38:24<26:26,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 970: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The passage states', 'Yes. The passage states']\n",
      "GPU memory after batch 970: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  81%|████████  | 972/1200 [2:38:30<25:55,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 971: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  81%|████████  | 973/1200 [2:38:39<28:09,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 972: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  81%|████████  | 974/1200 [2:38:45<26:50,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 973: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  81%|████████▏ | 975/1200 [2:38:52<25:54,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 974: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  81%|████████▏ | 976/1200 [2:38:58<24:53,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 975: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  81%|████████▏ | 977/1200 [2:39:05<25:19,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 976: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  82%|████████▏ | 978/1200 [2:39:11<24:34,  6.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 977: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  82%|████████▏ | 979/1200 [2:39:18<24:12,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 978: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  82%|████████▏ | 980/1200 [2:39:24<24:20,  6.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 979: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  82%|████████▏ | 981/1200 [2:39:31<23:59,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 980: 原始预测: ['Yes. The passage contains', 'Yes. The passage contains', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The date \"', 'Yes\\nAnswer: Yes']\n",
      "GPU memory after batch 980: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  82%|████████▏ | 982/1200 [2:39:38<24:36,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 981: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  82%|████████▏ | 983/1200 [2:39:45<24:06,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 982: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  82%|████████▏ | 984/1200 [2:39:52<24:29,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 983: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  82%|████████▏ | 985/1200 [2:40:00<26:03,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 984: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  82%|████████▏ | 986/1200 [2:40:06<24:59,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 985: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  82%|████████▏ | 987/1200 [2:40:13<24:23,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 986: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  82%|████████▏ | 988/1200 [2:40:19<23:49,  6.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 987: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  82%|████████▏ | 989/1200 [2:40:26<23:02,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 988: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  82%|████████▎ | 990/1200 [2:40:32<22:31,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 989: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  83%|████████▎ | 991/1200 [2:40:39<23:10,  6.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 990: 原始预测: ['Yes. The passage mentions', 'Yes. The passage mentions', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 990: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  83%|████████▎ | 992/1200 [2:40:45<22:39,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 991: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  83%|████████▎ | 993/1200 [2:40:51<22:05,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 992: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  83%|████████▎ | 994/1200 [2:40:58<21:58,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 993: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  83%|████████▎ | 995/1200 [2:41:04<22:19,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 994: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  83%|████████▎ | 996/1200 [2:41:11<22:21,  6.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 995: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  83%|████████▎ | 997/1200 [2:41:19<24:01,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 996: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  83%|████████▎ | 998/1200 [2:41:26<23:13,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 997: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  83%|████████▎ | 999/1200 [2:41:32<22:28,  6.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 998: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  83%|████████▎ | 1000/1200 [2:41:39<22:21,  6.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 999: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  83%|████████▎ | 1001/1200 [2:41:45<21:42,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 1000: 原始预测: ['Yes. Answer: Yes', 'Yes. The value \"-', 'Yes. Answer: Yes', 'Yes. The number \"', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 1000: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  84%|████████▎ | 1002/1200 [2:41:51<21:26,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1001: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  84%|████████▎ | 1003/1200 [2:41:58<21:13,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1002: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  84%|████████▎ | 1004/1200 [2:42:05<21:27,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1003: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  84%|████████▍ | 1005/1200 [2:42:11<21:22,  6.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1004: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  84%|████████▍ | 1006/1200 [2:42:18<21:24,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1005: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  84%|████████▍ | 1007/1200 [2:42:24<21:12,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1006: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  84%|████████▍ | 1008/1200 [2:42:31<21:08,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1007: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  84%|████████▍ | 1009/1200 [2:42:40<23:05,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1008: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  84%|████████▍ | 1010/1200 [2:42:46<22:22,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1009: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  84%|████████▍ | 1011/1200 [2:42:53<21:29,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 1010: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The value \".', 'Yes. The value \".', 'Yes. Answer: Yes', 'Yes. The year \"']\n",
      "GPU memory after batch 1010: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  84%|████████▍ | 1012/1200 [2:42:59<20:51,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1011: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  84%|████████▍ | 1013/1200 [2:43:05<20:12,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1012: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  84%|████████▍ | 1014/1200 [2:43:11<19:50,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1013: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  85%|████████▍ | 1015/1200 [2:43:18<19:34,  6.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1014: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  85%|████████▍ | 1016/1200 [2:43:24<19:15,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1015: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  85%|████████▍ | 1017/1200 [2:43:30<19:32,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1016: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  85%|████████▍ | 1018/1200 [2:43:37<19:26,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1017: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  85%|████████▍ | 1019/1200 [2:43:43<19:04,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1018: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  85%|████████▌ | 1020/1200 [2:43:49<18:53,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1019: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  85%|████████▌ | 1021/1200 [2:43:57<20:35,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 1020: 原始预测: ['Yes\\nQuestion: Is', 'Yes\\nQuestion: Is', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 1020: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  85%|████████▌ | 1022/1200 [2:44:04<20:01,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1021: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  85%|████████▌ | 1023/1200 [2:44:10<19:43,  6.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1022: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  85%|████████▌ | 1024/1200 [2:44:17<19:15,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1023: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  85%|████████▌ | 1025/1200 [2:44:23<19:10,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1024: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  86%|████████▌ | 1026/1200 [2:44:29<18:33,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1025: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  86%|████████▌ | 1027/1200 [2:44:35<18:19,  6.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1026: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  86%|████████▌ | 1028/1200 [2:44:42<18:04,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1027: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  86%|████████▌ | 1029/1200 [2:44:48<18:03,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1028: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  86%|████████▌ | 1030/1200 [2:44:55<18:13,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1029: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  86%|████████▌ | 1031/1200 [2:45:01<18:06,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 1030: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The mention of', 'No. The \"0', 'Yes. The number \"', 'Yes. The number \"', 'Yes. The number \"', 'Yes. The value \"']\n",
      "GPU memory after batch 1030: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  86%|████████▌ | 1032/1200 [2:45:08<17:57,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1031: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  86%|████████▌ | 1033/1200 [2:45:15<19:05,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1032: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  86%|████████▌ | 1034/1200 [2:45:22<18:28,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1033: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  86%|████████▋ | 1035/1200 [2:45:28<18:22,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1034: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  86%|████████▋ | 1036/1200 [2:45:35<18:02,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1035: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  86%|████████▋ | 1037/1200 [2:45:41<18:00,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1036: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  86%|████████▋ | 1038/1200 [2:45:48<17:51,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1037: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  87%|████████▋ | 1039/1200 [2:45:54<17:26,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1038: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  87%|████████▋ | 1040/1200 [2:46:01<17:14,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1039: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  87%|████████▋ | 1041/1200 [2:46:07<16:54,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 1040: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The value \"', 'Yes. The division in']\n",
      "GPU memory after batch 1040: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  87%|████████▋ | 1042/1200 [2:46:13<16:33,  6.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1041: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  87%|████████▋ | 1043/1200 [2:46:19<16:32,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1042: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  87%|████████▋ | 1044/1200 [2:46:26<16:47,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1043: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  87%|████████▋ | 1045/1200 [2:46:35<18:28,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1044: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  87%|████████▋ | 1046/1200 [2:46:41<17:47,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1045: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  87%|████████▋ | 1047/1200 [2:46:48<17:36,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1046: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  87%|████████▋ | 1048/1200 [2:46:54<16:55,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1047: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  87%|████████▋ | 1049/1200 [2:47:00<16:25,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1048: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  88%|████████▊ | 1050/1200 [2:47:07<16:07,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1049: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  88%|████████▊ | 1051/1200 [2:47:13<16:10,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 1050: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The passage states', 'Yes. The passage states']\n",
      "GPU memory after batch 1050: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  88%|████████▊ | 1052/1200 [2:47:20<16:08,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1051: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  88%|████████▊ | 1053/1200 [2:47:26<15:49,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1052: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  88%|████████▊ | 1054/1200 [2:47:33<15:42,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1053: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  88%|████████▊ | 1055/1200 [2:47:39<15:34,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1054: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  88%|████████▊ | 1056/1200 [2:47:46<15:27,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1055: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  88%|████████▊ | 1057/1200 [2:47:54<16:43,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1056: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  88%|████████▊ | 1058/1200 [2:48:00<16:03,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1057: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  88%|████████▊ | 1059/1200 [2:48:07<15:40,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1058: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  88%|████████▊ | 1060/1200 [2:48:13<15:16,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1059: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  88%|████████▊ | 1061/1200 [2:48:20<15:19,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 1060: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The passage states', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 1060: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  88%|████████▊ | 1062/1200 [2:48:26<15:17,  6.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1061: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  89%|████████▊ | 1063/1200 [2:48:33<15:01,  6.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1062: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  89%|████████▊ | 1064/1200 [2:48:39<14:53,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1063: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  89%|████████▉ | 1065/1200 [2:48:46<14:34,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1064: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  89%|████████▉ | 1066/1200 [2:48:52<14:18,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1065: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  89%|████████▉ | 1067/1200 [2:48:58<14:03,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1066: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  89%|████████▉ | 1068/1200 [2:49:05<14:11,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1067: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  89%|████████▉ | 1069/1200 [2:49:13<15:26,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1068: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  89%|████████▉ | 1070/1200 [2:49:20<14:57,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1069: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  89%|████████▉ | 1071/1200 [2:49:26<14:22,  6.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 1070: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 1070: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  89%|████████▉ | 1072/1200 [2:49:32<14:05,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1071: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  89%|████████▉ | 1073/1200 [2:49:39<13:51,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1072: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  90%|████████▉ | 1074/1200 [2:49:45<13:32,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1073: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  90%|████████▉ | 1075/1200 [2:49:51<13:24,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1074: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  90%|████████▉ | 1076/1200 [2:49:58<13:12,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1075: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  90%|████████▉ | 1077/1200 [2:50:04<13:06,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1076: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  90%|████████▉ | 1078/1200 [2:50:10<12:59,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1077: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  90%|████████▉ | 1079/1200 [2:50:17<12:56,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1078: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  90%|█████████ | 1080/1200 [2:50:23<12:48,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1079: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  90%|█████████ | 1081/1200 [2:50:32<14:11,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 1080: 原始预测: ['Yes\\nQuestion: Is', 'Yes\\nQuestion: Is', 'Yes. Answer: Yes', 'Yes. The mention of', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes\\n\\nAnswer: Yes', 'Yes\\n\\nAnswer: Yes']\n",
      "GPU memory after batch 1080: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  90%|█████████ | 1082/1200 [2:50:39<13:46,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1081: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  90%|█████████ | 1083/1200 [2:50:45<13:23,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1082: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  90%|█████████ | 1084/1200 [2:50:52<12:54,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1083: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  90%|█████████ | 1085/1200 [2:50:58<12:47,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1084: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  90%|█████████ | 1086/1200 [2:51:05<12:37,  6.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1085: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  91%|█████████ | 1087/1200 [2:51:11<12:23,  6.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1086: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  91%|█████████ | 1088/1200 [2:51:18<12:11,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1087: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  91%|█████████ | 1089/1200 [2:51:26<12:47,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1088: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  91%|█████████ | 1090/1200 [2:51:32<12:37,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1089: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  91%|█████████ | 1091/1200 [2:51:40<12:39,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 1090: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes\\nAnswer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 1090: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  91%|█████████ | 1093/1200 [2:51:54<12:52,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1092: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  91%|█████████ | 1094/1200 [2:52:01<12:19,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1093: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  91%|█████████▏| 1095/1200 [2:52:09<12:49,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1094: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  91%|█████████▏| 1096/1200 [2:52:15<12:09,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1095: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  91%|█████████▏| 1097/1200 [2:52:21<11:38,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1096: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  92%|█████████▏| 1098/1200 [2:52:28<11:16,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1097: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  92%|█████████▏| 1099/1200 [2:52:34<11:12,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1098: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  92%|█████████▏| 1100/1200 [2:52:41<11:06,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1099: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  92%|█████████▏| 1101/1200 [2:52:47<10:52,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 1100: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The passage states', 'Yes. The passage states']\n",
      "GPU memory after batch 1100: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  92%|█████████▏| 1102/1200 [2:52:54<11:01,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1101: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  92%|█████████▏| 1103/1200 [2:53:01<10:49,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1102: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  92%|█████████▏| 1104/1200 [2:53:08<10:42,  6.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1103: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  92%|█████████▏| 1105/1200 [2:53:16<11:16,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1104: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  92%|█████████▏| 1106/1200 [2:53:23<11:00,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1105: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  92%|█████████▏| 1107/1200 [2:53:29<10:44,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1106: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  92%|█████████▏| 1108/1200 [2:53:36<10:23,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1107: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  92%|█████████▏| 1109/1200 [2:53:43<10:17,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1108: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  92%|█████████▎| 1110/1200 [2:53:49<10:00,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1109: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  93%|█████████▎| 1111/1200 [2:53:55<09:40,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 1110: 原始预测: ['Yes. Answer: Yes', 'Yes. The value \"', 'Yes. The number \"', 'Yes. The value \"', 'Yes. The passage contains', 'Yes. The value \"', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 1110: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  93%|█████████▎| 1112/1200 [2:54:02<09:30,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1111: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  93%|█████████▎| 1113/1200 [2:54:08<09:22,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1112: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  93%|█████████▎| 1114/1200 [2:54:14<09:06,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1113: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  93%|█████████▎| 1115/1200 [2:54:20<09:02,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1114: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  93%|█████████▎| 1116/1200 [2:54:27<08:56,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1115: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  93%|█████████▎| 1117/1200 [2:54:35<09:33,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1116: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  93%|█████████▎| 1118/1200 [2:54:41<09:14,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1117: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  93%|█████████▎| 1119/1200 [2:54:48<08:53,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1118: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  93%|█████████▎| 1120/1200 [2:54:54<08:43,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1119: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  93%|█████████▎| 1121/1200 [2:55:00<08:26,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 1120: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 1120: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  94%|█████████▎| 1122/1200 [2:55:07<08:24,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1121: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  94%|█████████▎| 1123/1200 [2:55:13<08:20,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1122: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  94%|█████████▎| 1124/1200 [2:55:19<08:06,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1123: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  94%|█████████▍| 1125/1200 [2:55:26<08:03,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1124: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  94%|█████████▍| 1126/1200 [2:55:32<07:56,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1125: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  94%|█████████▍| 1127/1200 [2:55:39<07:55,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1126: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  94%|█████████▍| 1128/1200 [2:55:45<07:39,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1127: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  94%|█████████▍| 1129/1200 [2:55:54<08:14,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1128: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  94%|█████████▍| 1130/1200 [2:56:00<07:52,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1129: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  94%|█████████▍| 1131/1200 [2:56:06<07:34,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 1130: 原始预测: ['Yes. The number \"', 'Yes. The number \"', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 1130: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  94%|█████████▍| 1132/1200 [2:56:13<07:27,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1131: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  94%|█████████▍| 1133/1200 [2:56:19<07:13,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1132: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  94%|█████████▍| 1134/1200 [2:56:25<07:02,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1133: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  95%|█████████▍| 1135/1200 [2:56:32<07:00,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1134: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  95%|█████████▍| 1136/1200 [2:56:38<06:50,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1135: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  95%|█████████▍| 1137/1200 [2:56:44<06:46,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1136: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  95%|█████████▍| 1138/1200 [2:56:51<06:32,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1137: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  95%|█████████▍| 1139/1200 [2:56:57<06:28,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1138: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  95%|█████████▌| 1140/1200 [2:57:03<06:17,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1139: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  95%|█████████▌| 1141/1200 [2:57:11<06:47,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 1140: 原始预测: ['No\\nQuestion: Is', 'No\\nQuestion: Is', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 1140: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  95%|█████████▌| 1142/1200 [2:57:18<06:29,  6.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1141: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  95%|█████████▌| 1143/1200 [2:57:24<06:16,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1142: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  95%|█████████▌| 1144/1200 [2:57:30<06:06,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1143: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  95%|█████████▌| 1145/1200 [2:57:37<05:54,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1144: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  96%|█████████▌| 1146/1200 [2:57:43<05:47,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1145: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  96%|█████████▌| 1147/1200 [2:57:50<05:47,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1146: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  96%|█████████▌| 1148/1200 [2:57:56<05:36,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1147: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  96%|█████████▌| 1149/1200 [2:58:04<05:49,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1148: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  96%|█████████▌| 1150/1200 [2:58:10<05:31,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1149: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  96%|█████████▌| 1151/1200 [2:58:16<05:17,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 1150: 原始预测: ['Yes. The \"1', 'Yes. The mention of', 'Yes. The passage mentions', 'Yes. The \"0', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 1150: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  96%|█████████▌| 1152/1200 [2:58:22<05:06,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1151: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  96%|█████████▌| 1153/1200 [2:58:31<05:29,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1152: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  96%|█████████▌| 1154/1200 [2:58:37<05:16,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1153: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  96%|█████████▋| 1155/1200 [2:58:44<05:06,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1154: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  96%|█████████▋| 1156/1200 [2:58:51<04:58,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1155: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  96%|█████████▋| 1157/1200 [2:58:57<04:43,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1156: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  96%|█████████▋| 1158/1200 [2:59:03<04:34,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1157: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  97%|█████████▋| 1159/1200 [2:59:10<04:30,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1158: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  97%|█████████▋| 1160/1200 [2:59:16<04:21,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1159: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  97%|█████████▋| 1161/1200 [2:59:23<04:15,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 1160: 原始预测: ['Yes. The passage states', 'Yes. The percentage \"', 'Yes. The mention of', 'Yes. The number \"', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The value \"', 'Yes. The value \"']\n",
      "GPU memory after batch 1160: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  97%|█████████▋| 1162/1200 [2:59:30<04:11,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1161: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  97%|█████████▋| 1163/1200 [2:59:37<04:15,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1162: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  97%|█████████▋| 1164/1200 [2:59:44<04:06,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1163: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  97%|█████████▋| 1165/1200 [2:59:52<04:15,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1164: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  97%|█████████▋| 1166/1200 [2:59:59<03:57,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1165: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  97%|█████████▋| 1167/1200 [3:00:05<03:45,  6.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1166: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  97%|█████████▋| 1168/1200 [3:00:12<03:36,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1167: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  97%|█████████▋| 1169/1200 [3:00:18<03:27,  6.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1168: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  98%|█████████▊| 1170/1200 [3:00:25<03:21,  6.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1169: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  98%|█████████▊| 1171/1200 [3:00:32<03:13,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 1170: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The mention of', 'Yes. Answer: Yes', 'Yes. The \"9', 'Yes. Answer: Yes', 'Yes. The passage mentions', 'Yes. The date \"']\n",
      "GPU memory after batch 1170: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  98%|█████████▊| 1172/1200 [3:00:38<03:03,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1171: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  98%|█████████▊| 1173/1200 [3:00:44<02:56,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1172: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  98%|█████████▊| 1174/1200 [3:00:51<02:49,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1173: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  98%|█████████▊| 1175/1200 [3:00:58<02:48,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1174: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  98%|█████████▊| 1176/1200 [3:01:05<02:41,  6.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1175: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  98%|█████████▊| 1177/1200 [3:01:13<02:44,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1176: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  98%|█████████▊| 1178/1200 [3:01:19<02:30,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1177: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  98%|█████████▊| 1179/1200 [3:01:26<02:22,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1178: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  98%|█████████▊| 1180/1200 [3:01:33<02:15,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1179: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  98%|█████████▊| 1181/1200 [3:01:39<02:06,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 1180: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes\\nAnswer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 1180: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  98%|█████████▊| 1182/1200 [3:01:46<01:59,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1181: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  99%|█████████▊| 1183/1200 [3:01:52<01:52,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1182: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  99%|█████████▊| 1184/1200 [3:01:58<01:44,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1183: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  99%|█████████▉| 1185/1200 [3:02:05<01:37,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1184: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  99%|█████████▉| 1186/1200 [3:02:11<01:31,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1185: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  99%|█████████▉| 1187/1200 [3:02:19<01:27,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1186: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  99%|█████████▉| 1188/1200 [3:02:25<01:18,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1187: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  99%|█████████▉| 1189/1200 [3:02:33<01:17,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1188: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  99%|█████████▉| 1190/1200 [3:02:39<01:07,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1189: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  99%|█████████▉| 1191/1200 [3:02:46<01:02,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 1190: 原始预测: ['Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. Answer: Yes', 'Yes. The number \"', 'Yes. The number \"', 'Yes. Answer: Yes', 'Yes. Answer: Yes']\n",
      "GPU memory after batch 1190: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  99%|█████████▉| 1192/1200 [3:02:53<00:54,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1191: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  99%|█████████▉| 1193/1200 [3:02:59<00:46,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1192: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|█████████▉| 1194/1200 [3:03:06<00:40,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1193: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|█████████▉| 1195/1200 [3:03:12<00:33,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1194: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|█████████▉| 1196/1200 [3:03:19<00:26,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1195: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|█████████▉| 1197/1200 [3:03:25<00:19,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1196: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|█████████▉| 1198/1200 [3:03:32<00:13,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1197: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|█████████▉| 1199/1200 [3:03:38<00:06,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1198: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 1200/1200 [3:03:44<00:00,  9.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory after batch 1199: 12.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测结果已保存到 /kaggle/working/predictions.jsonl\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/kaggle/input/benedect/BeNEDect_all.json\"  # 确认路径，必要时修改\n",
    "dataset = load_benedect_dataset(file_path)\n",
    "\n",
    "# 随机抽取一个样本进行单条推理\n",
    "random_sample = random.choice(dataset)\n",
    "print(\"=== 随机样本推理 ===\")\n",
    "print(f\"Passage: {random_sample['passage']}\")\n",
    "print(f\"Number: {random_sample['number']}\")\n",
    "print(f\"Expected Answer: {random_sample['expected_answer']}\")\n",
    "print(f\"Prompt Type: {random_sample['prompt_type']}\")\n",
    "print(f\"Prompt:\\n{random_sample['prompt']}\")\n",
    "\n",
    "random_pred = predict_single(random_sample['prompt'])\n",
    "print(f\"Raw Prediction: {random_pred}\")\n",
    "\n",
    "# 提取提示\n",
    "prompts = [item['prompt'] for item in dataset]\n",
    "\n",
    "# 进行批次推理\n",
    "predictions = predict_batch(prompts, batch_size=8, max_retries=3)\n",
    "\n",
    "# 保存预测结果到 JSONL\n",
    "output_file = \"/kaggle/working/predictions.jsonl\"  # 确认路径，必要时修改\n",
    "save_predictions_to_jsonl(dataset, predictions, output_file)\n",
    "print(f\"预测结果已保存到 {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_prediction(raw_prediction: str) -> str:\n",
    "    raw_prediction = raw_prediction.lower()\n",
    "    if 'yes' in raw_prediction:\n",
    "        return 'yes'\n",
    "    elif 'no' in raw_prediction:\n",
    "        return 'no'\n",
    "    else:\n",
    "        # print(f\"无法解析响应: {raw_prediction}\")\n",
    "        return 'generation_error'\n",
    "\n",
    "def evaluate_model(data_list: List[Dict], unparsed_output_file: str = 'unparsed_predictions.json') -> Tuple[Dict, Dict]:\n",
    "    metrics = Counter()\n",
    "    detailed_metrics = {\n",
    "        'by_domain': defaultdict(Counter),\n",
    "        'by_error_type': defaultdict(Counter),\n",
    "        'by_operation': defaultdict(Counter),\n",
    "        'by_prompt_type': defaultdict(Counter)\n",
    "    }\n",
    "    unparsed_data = {}  # 存储无法解析的样本，格式为 {id: {...}}\n",
    "    \n",
    "    for idx, item in enumerate(data_list):\n",
    "        expected = item['expected_answer'].lower()  # Yes/No 转为小写\n",
    "        pred = parse_prediction(item['raw_prediction'])\n",
    "        item['parsel_prediction'] = pred  # 保存解析结果\n",
    "        \n",
    "        # 如果无法解析，添加到 unparsed_data\n",
    "        if pred == 'generation_error':\n",
    "            # 只保存 expected_answer == \"Yes\" 的样本（错误样本）\n",
    "            if expected == 'yes':\n",
    "                sample_id = f\"unparsed_{idx}\"\n",
    "                unparsed_data[sample_id] = {\n",
    "                    \"error_number\": item['number'],\n",
    "                    \"error_passage\": item['passage'],\n",
    "                    \"dataset\": item['dataset'],\n",
    "                    \"operation\": item['operation'],\n",
    "                    \"error_annotation\": item['error_annotation'],\n",
    "                    # 以下字段需补充（若有正确数据）\n",
    "                    \"correct_number\": \"\",  # 需手动补充或从原始数据推导\n",
    "                    \"correct_passage\": \"\"  # 需手动补充或从原始数据推导\n",
    "                }\n",
    "        \n",
    "        domain = item['dataset']\n",
    "        operation = item['operation']\n",
    "        prompt_type = item['prompt_type']\n",
    "        error_types = [k for k, v in item['error_annotation'].items() if v > 0]\n",
    "        \n",
    "        # 计算总体指标\n",
    "        if pred == expected:\n",
    "            if expected == 'yes':\n",
    "                metrics['TP'] += 1\n",
    "                for et in error_types:\n",
    "                    detailed_metrics['by_error_type'][et]['TP'] += 1\n",
    "                detailed_metrics['by_domain'][domain]['TP'] += 1\n",
    "                detailed_metrics['by_operation'][operation]['TP'] += 1\n",
    "                detailed_metrics['by_prompt_type'][prompt_type]['TP'] += 1\n",
    "            else:  # expected == 'no'\n",
    "                metrics['TN'] += 1\n",
    "                for et in error_types:\n",
    "                    detailed_metrics['by_error_type'][et]['TN'] += 1\n",
    "                detailed_metrics['by_domain'][domain]['TN'] += 1\n",
    "                detailed_metrics['by_operation'][operation]['TN'] += 1\n",
    "                detailed_metrics['by_prompt_type'][prompt_type]['TN'] += 1\n",
    "        else:\n",
    "            if expected == 'yes':\n",
    "                metrics['FN'] += 1\n",
    "                for et in error_types:\n",
    "                    detailed_metrics['by_error_type'][et]['FN'] += 1\n",
    "                detailed_metrics['by_domain'][domain]['FN'] += 1\n",
    "                detailed_metrics['by_operation'][operation]['FN'] += 1\n",
    "                detailed_metrics['by_prompt_type'][prompt_type]['FN'] += 1\n",
    "            else:  # expected == 'no'\n",
    "                metrics['FP'] += 1\n",
    "                for et in error_types:\n",
    "                    detailed_metrics['by_error_type'][et]['FP'] += 1\n",
    "                detailed_metrics['by_domain'][domain]['FP'] += 1\n",
    "                detailed_metrics['by_operation'][operation]['FP'] += 1\n",
    "                detailed_metrics['by_prompt_type'][prompt_type]['FP'] += 1\n",
    "        \n",
    "        if pred == 'generation_error':\n",
    "            metrics['Generation Error'] += 1\n",
    "            for et in error_types:\n",
    "                detailed_metrics['by_error_type'][et]['Generation Error'] += 1\n",
    "            detailed_metrics['by_domain'][domain]['Generation Error'] += 1\n",
    "            detailed_metrics['by_operation'][operation]['Generation Error'] += 1\n",
    "            detailed_metrics['by_prompt_type'][prompt_type]['Generation Error'] += 1\n",
    "    \n",
    "    # 保存无法解析的数据到 JSON\n",
    "    if unparsed_data:\n",
    "        with open(unparsed_output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(unparsed_data, f, indent=2, ensure_ascii=False)\n",
    "        # print(f\"无法解析的 {len(unparsed_data)} 条数据已保存到 {unparsed_output_file}\")\n",
    "        print(\"注意：JSON 文件仅包含 expected_answer='Yes' 的样本，correct_number 和 correct_passage 需手动补充\")\n",
    "    else:\n",
    "        print(\"没有无法解析的数据\")\n",
    "    \n",
    "    total = len(data_list)\n",
    "    metrics['Accuracy'] = (metrics['TP'] + metrics['TN']) / total if total > 0 else 0\n",
    "    return metrics, detailed_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "注意：JSON 文件仅包含 expected_answer='Yes' 的样本，correct_number 和 correct_passage 需手动补充\n",
      "\n",
      "Overall Metrics:\n",
      "FP: 4644 (0.484)\n",
      "TP: 4443 (0.463)\n",
      "TN: 156 (0.016)\n",
      "FN: 357 (0.037)\n",
      "Generation Error: 577 (0.060)\n",
      "Accuracy: 0.479\n",
      "\n",
      "Metrics by Domain:\n",
      "Numeracy_600K_article_title: {'FP': 966, 'TP': 984, 'TN': 34, 'FN': 16}\n",
      "aclsent: {'FP': 896, 'TP': 931, 'TN': 52, 'FN': 17}\n",
      "DROP: {'FP': 973, 'TP': 700, 'TN': 21, 'Generation Error': 569, 'FN': 294}\n",
      "qa-text-source-comparison: {'FP': 901, 'TP': 905, 'TN': 23, 'FN': 19, 'Generation Error': 8}\n",
      "FinNum: {'FP': 908, 'TP': 923, 'TN': 26, 'FN': 11}\n",
      "\n",
      "Metrics by Error Type:\n",
      "Error in Number Relationships: {'FP': 193, 'TP': 192, 'TN': 3, 'FN': 4, 'Generation Error': 6}\n",
      "Undetectable Error: {'FP': 453, 'TP': 445, 'TN': 11, 'FN': 19, 'Generation Error': 18}\n",
      "Type Error: {'FP': 499, 'TP': 508, 'TN': 19, 'FN': 10, 'Generation Error': 16}\n",
      "Anomaly: {'FP': 223, 'TP': 219, 'FN': 11, 'TN': 7, 'Generation Error': 14}\n",
      "Improper Data: {'FP': 28, 'TP': 29, 'TN': 1}\n",
      "Factual Error: {'FP': 55, 'TP': 55, 'TN': 2, 'FN': 2, 'Generation Error': 2}\n",
      "\n",
      "Metrics by Operation:\n",
      "*2: {'FP': 153, 'TP': 146, 'TN': 6, 'FN': 13, 'Generation Error': 22}\n",
      "-10: {'FP': 175, 'TP': 167, 'TN': 8, 'FN': 16, 'Generation Error': 22}\n",
      "+1: {'FP': 182, 'TP': 174, 'TN': 6, 'FN': 14, 'Generation Error': 18}\n",
      "*0.9: {'FP': 182, 'TP': 171, 'TN': 4, 'Generation Error': 28, 'FN': 15}\n",
      "*1.1: {'FP': 190, 'TP': 180, 'TN': 9, 'FN': 19, 'Generation Error': 34}\n",
      "-0.5: {'FP': 149, 'TP': 148, 'TN': 7, 'Generation Error': 11, 'FN': 8}\n",
      "+1000: {'FP': 157, 'TP': 146, 'Generation Error': 24, 'FN': 13, 'TN': 2}\n",
      "*1.5: {'FP': 161, 'TP': 156, 'TN': 3, 'Generation Error': 14, 'FN': 8}\n",
      "*0.1: {'FP': 155, 'TP': 152, 'TN': 6, 'FN': 9, 'Generation Error': 12}\n",
      "*0: {'FP': 174, 'TP': 161, 'TN': 4, 'FN': 17, 'Generation Error': 24}\n",
      "-0.1: {'FP': 186, 'TP': 173, 'TN': 2, 'Generation Error': 30, 'FN': 15}\n",
      "swap: {'FP': 338, 'TP': 318, 'TN': 10, 'FN': 30, 'Generation Error': 42}\n",
      "*0.01: {'FP': 174, 'TP': 172, 'TN': 7, 'Generation Error': 14, 'FN': 9}\n",
      "+10: {'FP': 169, 'TP': 162, 'TN': 5, 'FN': 12, 'Generation Error': 20}\n",
      "+0.1: {'FP': 155, 'TP': 149, 'TN': 8, 'FN': 14, 'Generation Error': 17}\n",
      "*(-1): {'FP': 154, 'TP': 147, 'TN': 6, 'FN': 13, 'Generation Error': 24}\n",
      "-1: {'FP': 195, 'TP': 189, 'TN': 5, 'FN': 11, 'Generation Error': 18}\n",
      "*0.5: {'FP': 202, 'TP': 193, 'TN': 7, 'FN': 16, 'Generation Error': 20}\n",
      "*100: {'FP': 156, 'TP': 144, 'FN': 17, 'TN': 5, 'Generation Error': 29}\n",
      "+0.5: {'FP': 161, 'TP': 154, 'TN': 8, 'Generation Error': 27, 'FN': 15}\n",
      "-1000: {'FP': 160, 'TP': 149, 'TN': 4, 'Generation Error': 30, 'FN': 15}\n",
      "-100: {'FP': 148, 'TP': 144, 'FN': 11, 'TN': 7, 'Generation Error': 16}\n",
      "*0.001: {'FP': 151, 'TP': 147, 'TN': 6, 'Generation Error': 20, 'FN': 10}\n",
      "*0.7: {'FP': 125, 'TP': 120, 'TN': 4, 'FN': 9, 'Generation Error': 13}\n",
      "*1000: {'FP': 167, 'TP': 162, 'TN': 4, 'Generation Error': 18, 'FN': 9}\n",
      "+100: {'FP': 158, 'TP': 155, 'TN': 7, 'FN': 10, 'Generation Error': 14}\n",
      "*10: {'FP': 167, 'TP': 164, 'TN': 6, 'FN': 9, 'Generation Error': 16}\n",
      "\n",
      "Metrics by Prompt Type:\n",
      "few_shot: {'FP': 34, 'TP': 55, 'TN': 66, 'FN': 45, 'Generation Error': 18}\n",
      "zero_shot: {'FP': 4610, 'TP': 4388, 'FN': 312, 'TN': 90, 'Generation Error': 559}\n"
     ]
    }
   ],
   "source": [
    "# 读取 predictions.jsonl\n",
    "data_list = []\n",
    "input_file = 'qwen_3_predictions.jsonl'  # 确认路径\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        data_list.append(data)\n",
    "\n",
    "# 评测模型并保存无法解析的数据\n",
    "unparsed_output_file = 'qwen_3_unparsed_predictions.json'\n",
    "metrics, detailed_metrics = evaluate_model(data_list, unparsed_output_file)\n",
    "\n",
    "# 打印总体指标\n",
    "print(\"\\nOverall Metrics:\")\n",
    "total = len(data_list)\n",
    "for key, value in metrics.items():\n",
    "    if key == 'Accuracy':\n",
    "        print(f\"{key}: {value:.3f}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value} ({value / total:.3f})\")\n",
    "\n",
    "# 打印分维度指标\n",
    "print(\"\\nMetrics by Domain:\")\n",
    "for domain, counts in detailed_metrics['by_domain'].items():\n",
    "    print(f\"{domain}: {dict(counts)}\")\n",
    "\n",
    "print(\"\\nMetrics by Error Type:\")\n",
    "for error_type, counts in detailed_metrics['by_error_type'].items():\n",
    "    print(f\"{error_type}: {dict(counts)}\")\n",
    "\n",
    "print(\"\\nMetrics by Operation:\")\n",
    "for operation, counts in detailed_metrics['by_operation'].items():\n",
    "    print(f\"{operation}: {dict(counts)}\")\n",
    "\n",
    "print(\"\\nMetrics by Prompt Type:\")\n",
    "for prompt_type, counts in detailed_metrics['by_prompt_type'].items():\n",
    "    print(f\"{prompt_type}: {dict(counts)}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7381062,
     "sourceId": 11757485,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "temp_train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
